+++
title = 'Paper Reading: Spade Synthesizing Assertions for Large Language Model Pipelines'
date = 2024-03-01T20:26:39-05:00
draft = false
tags = ['Paper Reading']
+++

## SPADE: Synthesizing Assertions for Large Language Model Pipelines

Synthesizing Assertions

Pipelines

> åˆæˆæ–­è¨€ã€æµæ°´çº¿

## ABSTRACT

å°†å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰ç”¨äºŽå®šåˆ¶ã€é‡å¤æ•°æ® pipeline çš„æ“ä½œå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«æ˜¯ç”±äºŽå…¶**ä¸å¯é¢„æµ‹å’Œæ½œåœ¨çš„ç¾éš¾æ€§æ•…éšœ**ã€‚è®¤è¯†åˆ°è¿™äº›é”™è¯¯çš„ä¸å¯é¿å…æ€§ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨è¯†åˆ« LLM åœ¨ä½œä¸ºæ•°æ®ç”Ÿæˆ pipeline çš„ä¸€éƒ¨åˆ†é‡å¤ä½¿ç”¨æ—¶å¯èƒ½**ç”Ÿæˆé”™è¯¯å“åº”**çš„æƒ…å†µã€‚æˆ‘ä»¬æå‡ºäº† spadeï¼Œä¸€ç§è‡ªåŠ¨åˆæˆæ–­è¨€çš„æ–¹æ³•ï¼Œå¯ä»¥è¯†åˆ«ä¸è‰¯çš„ LLM è¾“å‡ºã€‚SPADE åˆ†æžæç¤ºç‰ˆæœ¬åŽ†å²ï¼Œ**åˆ›å»ºå€™é€‰æ–­è¨€å‡½æ•°**ï¼Œç„¶åŽ**é€‰æ‹©æ»¡è¶³è¦†ç›–çŽ‡å’Œå‡†ç¡®æ€§è¦æ±‚çš„æœ€å°é›†åˆ**ã€‚åœ¨å¯¹ä¹ç§ä¸åŒçš„å®žé™… LLM pipeline è¿›è¡Œæµ‹è¯•æ—¶ï¼Œä¸Žç®€å•çš„åŸºçº¿ç›¸æ¯”ï¼Œspade æœ‰æ•ˆåœ°**å‡å°‘äº† 14% çš„æ–­è¨€æ•°é‡**ï¼Œå¹¶å°†**é”™è¯¯å¤±è´¥çŽ‡é™ä½Žäº† 21%ã€‚**

## INTRODUCTION

åœ¨æ•°æ® pipeline ä¸­ä½¿ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰å¼•èµ·äº†å¹¿æ³›å…³æ³¨[17]ã€‚è¿™ç§çƒ­æƒ…å¾ˆå¤§ç¨‹åº¦ä¸Šå½’åŠŸäºŽå…¶ç®€å•æ€§ï¼šæ— éœ€å¤§åž‹æ ‡æ³¨æ•°æ®é›†ï¼Œåªéœ€ç”¨è‡ªç„¶è¯­è¨€æç¤º LLMï¼Œå°±èƒ½è½»æ¾åˆ›å»ºä¸€ä¸ª**è‡ªåŠ¨åŒ–çš„æ™ºèƒ½ pipeline **ï¼Œåœ¨æ•°ç§’å†…æ‰§è¡Œä»»æ„æ•°æ®ç”Ÿæˆä»»åŠ¡ã€‚ç„¶è€Œï¼Œå°† LLM ç”¨äºŽæ— ç›‘ç£ã€é‡å¤æˆ–å¤§è§„æ¨¡çš„æ•°æ®ç”Ÿæˆä»»åŠ¡å´é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜[34]ï¼Œä¾‹å¦‚**æ½œåœ¨çš„é”™è¯¯ã€ä¸æ°å½“çš„ååº”æˆ–å¹»è§‰**[44, 57]ã€‚

> Data Management For Large Language Models: A Surveyï¼Œæ²¡å¤ªç†è§£å¼•ç”¨è¿™ç¯‡è®ºæ–‡çš„æ„æ€ï¼Œæ˜¯åœ¨é¢„è®­ç»ƒã€å¾®è°ƒæ—¶ç®¡ç†æ•°æ®
>
> ç”¨ LLM åˆ¶ä½œåº”ç”¨æ—¶ï¼Œå§‹ç»ˆæ— æ³•é¿å… potential errors, inappropriate responses, or hallucination

è€ƒè™‘ä½¿ç”¨ LLM ç”Ÿæˆä¸ªæ€§åŒ–ç”µå½±æŽ¨èè¯´æ˜Žçš„ç”µå½±æµåª’ä½“å¹³å°ã€‚å¼€å‘äººå‘˜å¯èƒ½ä¼šç¼–å†™ç±»ä¼¼çš„æç¤ºæ¨¡æ¿ï¼š "æ ¹æ®ç”¨æˆ·çš„ä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·åº”è¯¥è§‚çœ‹ {movie_name} çš„åŽŸå› ç¼–å†™ä¸ªæ€§åŒ–è¯´æ˜Žï¼š {personal_info}"è¿™æ ·çš„æç¤ºæ¨¡æ¿ï¼Œé’ˆå¯¹å¤šä¸ªç”¨æˆ·-ç”µå½±é…å¯¹æ‰§è¡Œã€‚æ¨¡æ¿åŒ–å˜é‡ä»£è¡¨çš„ä¿¡æ¯å°†åœ¨è¿è¡Œæ—¶æ³¨å…¥ pipeline ï¼Œä½¿ pipeline èƒ½å¤Ÿä¸ºå„ç§è¾“å…¥ç”Ÿæˆæ•°æ®ã€‚ä»Žç†è®ºä¸Šè®²ï¼Œè¿™ç§æç¤ºä¼¼ä¹Žè¶³å¤Ÿäº†ï¼Œä½†å¼€å‘äººå‘˜åœ¨å¯¹ä¸€äº›ç¤ºä¾‹è¾“å…¥è¿›è¡Œæµ‹è¯•æ—¶å¯èƒ½ä¼šå‘çŽ°ä¸€äº›é—®é¢˜ï¼šLLM å¯èƒ½ä¼šå¼•ç”¨ç”¨æˆ·ä»Žæœªçœ‹è¿‡çš„ç”µå½±ï¼Œå¼•ç”¨æ•æ„Ÿå±žæ€§ï¼ˆå¦‚ç§æ—æˆ–æ°‘æ—ï¼‰ï¼Œç”šè‡³å‡ºçŽ°å“åº”è¿‡çŸ­ç­‰åŸºæœ¬é—®é¢˜ã€‚

ä¸ºäº†è§£å†³è¿™äº›ç¼ºé™·ï¼Œæœ‰äººæå‡ºäº†åœ¨ LLM pipeline ä¸­åŠ å…¥æ–­è¨€ assertions çš„æ¡†æž¶ï¼Œ**ä»¥ä¾¿åœ¨åˆ°è¾¾æœ€ç»ˆç”¨æˆ·ä¹‹å‰è¿‡æ»¤æŽ‰ä¸è‰¯ç”Ÿæˆ**[37, 49]ã€‚é‰´äºŽ LLM é”™è¯¯çš„ä¸å¯é¿å…æ€§[23]ï¼Œæ­¤ç±»æ–­è¨€æ˜¯æˆåŠŸéƒ¨ç½²ç”Ÿæˆæ•°æ®çš„ LLM pipeline çš„å…³é”®ã€‚ç„¶è€Œï¼Œå¼€å‘äººå‘˜å‘çŽ°ä¸ºè‡ªå®šä¹‰ LLM pipeline ç¼–å†™æ–­è¨€éžå¸¸å›°éš¾ [35]ã€‚é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬ï¼š**é¢„æµ‹æ‰€æœ‰å¯èƒ½çš„ LLM æ•…éšœæ¨¡å¼**ï¼›ä½¿ç”¨å„ç§**è§„èŒƒæ–¹æ³•**ï¼ˆå¦‚ Python å‡½æ•°æˆ– LLM è°ƒç”¨ï¼‰ç¼–å†™æ–­è¨€è€—æ—¶ï¼›æ–­è¨€ï¼ˆå°¤å…¶æ˜¯æ¶‰åŠ LLM è°ƒç”¨çš„æ–­è¨€ï¼‰**å¿…é¡»ç²¾ç¡®**ï¼›ä»¥åŠè®¸å¤š LLM pipeline å¼€å‘äººå‘˜ç¼ºä¹è½¯ä»¶å·¥ç¨‹ä¸“ä¸šçŸ¥è¯†æˆ–ç¼–ç ç»éªŒ [26ï¼Œ57]ã€‚æ­¤å¤–ï¼Œå¦‚æžœæ–­è¨€è¿‡å¤šæˆ–ä¸å…·ä¿¡æ¯æ€§ï¼Œå¼€å‘äººå‘˜åœ¨ç›‘æŽ§å…¶ç»“æžœæ—¶å¯èƒ½ä¼šä¸çŸ¥æ‰€æŽª

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‘çŽ°äº†ä¸€ä¸ªæ–°é—®é¢˜ï¼Œå³å¦‚ä½•ä¸ºä»»ä½•åˆ©ç”¨ LLM çš„æ•°æ®ç”Ÿæˆ pipeline **è‡ªåŠ¨ç”Ÿæˆä¸€ç»„å¥½çš„æ–­è¨€**ã€‚å¯¹äºŽ LLM å“åº”ï¼Œä¸€ä¸ªæ–­è¨€è¿”å›žçœŸï¼ˆå³æˆåŠŸï¼‰æˆ–å‡ï¼ˆå³å¤±è´¥ï¼‰ï¼Œè€Œä¸€ç»„æ–­è¨€åˆ™è¿”å›žå•ä¸ªæ–­è¨€çš„è”ç»“ã€‚ä¸€ç»„ "å¥½ "çš„æ–­è¨€å…·æœ‰æœ€å°çš„é‡å ï¼Œå…è®¸å¼€å‘äººå‘˜åœ¨é”™è¯¯çš„æˆåŠŸå’Œé”™è¯¯çš„å¤±è´¥ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚æˆ‘ä»¬å°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªéƒ¨åˆ†--å€™é€‰æ–­è¨€ç”Ÿæˆå’Œè¿‡æ»¤ candidate assertion generation and filtering --å¹¶æå‡ºäº† spadeï¼ˆ System for Prompt Analysis and Delta-Based Evaluation å›¾ 1ï¼‰ã€‚

![å›¾ 1](https://s2.loli.net/2024/03/03/lgh8FAURaXPZzoE.png)

> delta åœ¨è¿™é‡Œæ˜¯ diff çš„æ„æ€ï¼Ÿ
>
> candidate assertion å’Œ filtering éƒ½æ˜¯æ€Žä¹ˆå®žçŽ°çš„ï¼Ÿçœ‹ä¸ŠåŽ»è¿˜æ˜¯ LLM å®žçŽ°çš„

å¯¹äºŽå€™é€‰æ–­è¨€çš„ç”Ÿæˆï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘ç›´æŽ¥è¯¢é—® LLM "ä¸º x æç¤ºç¼–å†™æ–­è¨€"ï¼Œä½†è¿™å¯èƒ½æ— æ³•æ»¡è¶³å¼€å‘äººå‘˜çš„è¦æ±‚ã€‚æˆ‘ä»¬å»ºè®®ä»Ž prompt deltasï¼ˆå³ä¸¤ä¸ªè¿žç»­æç¤ºç¬¦ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ï¼‰ä¸­ç”Ÿæˆ**å€™é€‰æ–­è¨€**ï¼Œè¿™é€šå¸¸è¡¨ç¤º LLM çš„ç‰¹å®šæ•…éšœæ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œå¼€å‘äººå‘˜å¯èƒ½ä¼šæ·»åŠ ç±»ä¼¼ "é¿å…èŠ±å“¨è¯­è¨€ "çš„æŒ‡ä»¤ï¼Œä»Žè€Œä¿ƒä½¿æ–­è¨€æ£€æŸ¥å“åº”è¯­è¨€ã€‚æˆ‘ä»¬å¯¹æ¥è‡ª LangChainï¼ˆä¸€å®¶å¸®åŠ©äººä»¬æž„å»º LLM pipeline çš„åˆåˆ›å…¬å¸ï¼‰ç”¨æˆ·çš„ 19 ä¸ªè‡ªå®šä¹‰æ•°æ®ç”Ÿæˆ pipeline å’Œ pipeline æç¤ºç‰ˆæœ¬åŽ†å²è¿›è¡Œäº†åˆ†æžï¼Œä»Žè€Œå½¢æˆäº†ä¸€ä¸ª a taxonomy of prompt deltasã€‚Spade é¦–å…ˆåœ¨åˆ†ç±»æ³•ä¸­è‡ªåŠ¨å¯¹æç¤ºè„±èŠ‚è¿›è¡Œåˆ†ç±»ï¼Œç„¶åŽå°† Python å‡½æ•°ï¼ˆå¯èƒ½åŒ…æ‹¬ LLM è°ƒç”¨ï¼‰åˆæˆä¸ºå¯ç”¨æ–­è¨€ã€‚æˆ‘ä»¬å…¬å¼€å‘å¸ƒäº† SPADE çš„è¿™ä¸€ç»„ä»¶ï¼Œå±•ç¤ºäº†è¿™äº›æ–­è¨€çš„æ½œåŠ›ï¼Œå®ƒåœ¨é‡‘èžã€åŒ»è¯å’Œ IT ç­‰ 10 å¤šä¸ªé¢†åŸŸæœ‰ 1300 å¤šä¸ªç”¨é€” [46] ã€‚

> åœ¨ [langchain](https://blog.langchain.dev/spade-automatically-digging-up-evals-based-on-prompt-refinements/) ä¸Šçš„ SPADE ä¾‹å­

æˆ‘ä»¬å¯¹å€™é€‰æ–­è¨€çš„åˆ†æžå‘çŽ°äº†å†—ä½™ã€ä¸å‡†ç¡®å’Œå¤§é‡å‡½æ•°ï¼Œä»…å‡ ä¸ª prompt deltas å°±å¾€å¾€è¶…è¿‡ 50 ä¸ªã€‚å†—ä½™æºäºŽå¯¹æç¤ºç›¸ä¼¼éƒ¨åˆ†çš„é‡å¤å®Œå–„ï¼Œæˆ–æç¤ºæŒ‡ä»¤å«ç³Šä¸æ¸…ï¼ˆå¦‚ "è¿”å›žä¸€ä¸ªç®€æ´çš„å›žå¤"ï¼‰ã€‚å‡å°‘å†—ä½™å¹¶ä¸ç®€å•ï¼Œå³ä½¿å¯¹å·¥ç¨‹å¸ˆæ¥è¯´ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå› ä¸ºæ–­è¨€å¯èƒ½æ¶‰åŠç²¾ç¡®åº¦ä¸åŒçš„ LLM è°ƒç”¨ï¼Œè¿™å°±éœ€è¦ä¸€ä¸ªè‡ªåŠ¨è¿‡æ»¤ç»„ä»¶ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨**å¼€å‘äººå‘˜æ ‡è®°**çš„ LLM å“åº”æ¥ä¼°ç®—æ¯ä¸ªæ–­è¨€çš„**é”™è¯¯å¤±è´¥çŽ‡**ï¼ˆfalse failure rate FFRï¼‰ï¼Œå¹¶å‰”é™¤æ¯ä¸ªè¶…è¿‡å¼€å‘äººå‘˜å®šä¹‰çš„ FFR é˜ˆå€¼çš„æ–­è¨€ã€‚ç„¶è€Œï¼Œå…¶ä½™æ–­è¨€çš„ FFR å¯èƒ½ä¼šç´¯è®¡è¶…è¿‡è¿™ä¸ªé˜ˆå€¼ï¼Œå†—ä½™å¯èƒ½ä¼šæŒç»­å­˜åœ¨ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜Žï¼Œé€‰æ‹©ä¸€å°éƒ¨åˆ†æ–­è¨€æ¥æ»¡è¶³æ•…éšœè¦†ç›–çŽ‡å’Œ FFR æ ‡å‡†æ˜¯ NP-hard çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨**æ•´æ•°çº¿æ€§è§„åˆ’**ï¼ˆILPï¼‰æ¥è¡¨è¾¾è¿™ä¸ªé—®é¢˜ï¼Œå¹¶ä½¿ç”¨ ILP æ±‚è§£å™¨æ¥æ‰¾å‡ºè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘çŽ°æ ‡è®°çš„å“åº”å¯èƒ½æ— æ³•ä»£è¡¨æ‰€æœ‰æ•…éšœæ¨¡å¼ï¼Œä»Žè€Œå¯¼è‡´é—æ¼æœ‰ä»·å€¼çš„æ–­è¨€ã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„ç”µå½±æŽ¨èåœºæ™¯ä¸­ï¼Œå¦‚æžœå¼€å‘äººå‘˜æ ‡æ³¨æ ·æœ¬ä¸­çš„æ‰€æœ‰å›žå¤éƒ½ä½ŽäºŽ 200 å­—ï¼Œé‚£ä¹ˆèƒ½å¤Ÿæ­£ç¡®éªŒè¯ LLM ç”Ÿæˆçš„æ³¨é‡Šæ˜¯å¦å°‘äºŽ 200 å­—çš„æ–­è¨€å°±ä¼šè¢«æ”¾å¼ƒã€‚ä¸ºäº†æ‰©å¤§è¦†ç›–èŒƒå›´ï¼Œå¯ä»¥ä½¿ç”¨**ä¸»åŠ¨å­¦ä¹ **å’Œ**å¼±ç›‘ç£**æ–¹æ³•ä¸ºæ¯ä¸ªå€™é€‰æ–­è¨€é‡‡æ ·å’Œæ ‡æ³¨æ–°çš„ LLM æç¤º-å“åº”å¯¹ï¼Œä½†è¿™å¯èƒ½å¾ˆæ˜‚è´µï¼Œæˆ–è€…éžç¨‹åºå‘˜æ— æ³•ä½¿ç”¨ã€‚æˆ‘ä»¬å¼•å…¥äº†æ–­è¨€å­å—ï¼ˆassertion subsump-tionï¼‰ä½œä¸ºç¡®ä¿å…¨é¢è¦†ç›–çš„ä¸€ç§æ–¹æ³•ï¼šå¦‚æžœä¸€ä¸ªæ–­è¨€ä¸åŒ…å«å¦ä¸€ä¸ªæ–­è¨€çš„æ•…éšœæ¨¡å¼ï¼Œé‚£ä¹ˆä¸¤ä¸ªæ–­è¨€éƒ½ä¼šè¢«é€‰ä¸­ã€‚å› æ­¤ï¼ŒSPADE ä¼šé€‰æ‹©ä¸€ç»„æœ€å°çš„æ–­è¨€ï¼Œå¹¶**éµå®ˆæ•…éšœè¦†ç›–çŽ‡ã€å‡†ç¡®æ€§å’Œå­é›†çº¦æŸ**ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬åšå‡ºäº†ä»¥ä¸‹è´¡çŒ®ï¼š

> Todayâ€™s research release of ChatGPT is the latest step in OpenAIâ€™s iterative deployment of increasingly safe and useful AI systems. Many lessons from deployment of earlier models like GPT-3 and Codex have informed the safety mitigations in place for this release, including substantial reductions in harmful and untruthful outputs achieved by the use of reinforcement learning from human feedback (RLHF).
>
> https://openai.com/blog/chatgpt?ref=blog.cg-wire.com
>
> OpenAI ç”¨ RL å’Œäººå·¥ç›‘ç£ï¼Œæ¥è§„é¿ä¸€äº›å®‰å…¨é—®é¢˜å’Œå‡å°‘ä¸çœŸå®žè¾“å‡º

**Prompt Deltas** for Candidate Assertion Generationï¼šæˆ‘ä»¬å‘çŽ° **prompt version history æ˜¯æ•°æ®ç”Ÿæˆ LLM pipeline æ­£ç¡®æ€§æ ‡å‡†çš„ä¸°å¯Œæ¥æº**ã€‚æˆ‘ä»¬æ ¹æ® 19 ä¸ªå…·æœ‰ç‰ˆæœ¬åŽ†å²çš„ LLM pipeline çš„æŽ¨æ–­å‡ºäº†æ–­è¨€æ ‡å‡†åˆ†ç±»æ³•ï¼Œå¹¶å°†å…¶å…¬å¸ƒäºŽä¼—ã€‚æˆ‘ä»¬å…¬å¼€å‘å¸ƒäº†ä¸€æ¬¾å·¥å…·ï¼Œç”¨äºŽä¸ºä»»ä½• pipeline ç”Ÿæˆå€™é€‰æ–­è¨€ï¼Œé€šè¿‡ 1300 å¤šæ¬¡éƒ¨ç½²ä¸ºè‡ªåŠ¨ç”Ÿæˆæ–­è¨€çš„å®žç”¨æ€§æä¾›äº†æ—©æœŸè¯æ®ï¼ŒåŒæ—¶ä¹Ÿä¸ºç­›é€‰è¿™äº›æ–­è¨€æä¾›äº†æœºä¼šã€‚

**Filtering Method** that Requires Little Data: æˆ‘ä»¬è¯æ˜Žï¼Œåœ¨è¦†ç›–æ•…éšœæ¨¡å¼å’Œæ»¡è¶³å‡†ç¡®æ€§è¦æ±‚çš„å‰æä¸‹ï¼Œé€‰æ‹©**æœ€å°çš„æ–­è¨€é›†**æ˜¯ä¸€ä¸ª NP-Hardã€‚æˆ‘ä»¬å°†è¿™ä¸€é—®é¢˜è¡¨è¿°ä¸º ILPã€‚é‰´äºŽæ–­è¨€å¯èƒ½æ˜¯å†—ä½™å’Œä¸å‡†ç¡®çš„ï¼Œè€Œä¸” LLM å¼€å‘äººå‘˜å¯èƒ½ä¸å…·å¤‡å·¥ç¨‹ä¸“ä¸šçŸ¥è¯†æˆ–è¶³å¤Ÿçš„æ•°æ®æ¥ä½¿ç”¨çŽ°æœ‰çš„æ•°æ®é©±åŠ¨æ–¹æ³•è¿›è¡Œ ML pipeline æµ‹è¯•ï¼ˆå¦‚è®­ç»ƒæ¨¡åž‹ï¼‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ–­è¨€å½’å¹¶ä½œä¸ºåœ¨ä½Žæ•°æ®é‡çŽ¯å¢ƒä¸‹è¦†ç›–çŽ‡çš„**æ–°åž‹æ›¿ä»£æ–¹æ³•**ã€‚

Empirical Study: æˆ‘ä»¬ä»‹ç»äº† spadeï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸ºæ•°æ®ç”Ÿæˆ LLM pipeline è‡ªåŠ¨ç”Ÿæˆæ–­è¨€çš„ç³»ç»Ÿã€‚å¯¹äºŽä¹ä¸ªå…·æœ‰æç¤ºç‰ˆæœ¬åŽ†å²çš„ LLM pipeline ï¼Œæˆ‘ä»¬æ”¶é›†äº†å¸¦æ ‡ç­¾çš„ prompt-response pairsï¼ˆå…¶ä¸­å…«ä¸ªå·²å¼€æºï¼‰ã€‚

![alt text](image.png)

> https://spade-beta.streamlit.app/

åœ¨æ‰€æœ‰ pipelines ä¸­ï¼ŒSpade ç”Ÿæˆçš„æ–­è¨€éƒ½å…·æœ‰ good failure coverage å’Œ few false failuresï¼ˆå³æ— æ³•åšå‡ºè‰¯å¥½å“åº”ï¼‰ã€‚æˆ‘ä»¬åŸºäºŽå­å‡è®¾çš„ ILP ä¼˜äºŽä¸è€ƒè™‘æ–­è¨€é—´äº¤äº’çš„ç®€å•åŸºçº¿ï¼Œå‡å°‘äº† 14% çš„æ–­è¨€ï¼Œé™ä½Žäº† 21% çš„é”™è¯¯å¤±è´¥çŽ‡ã€‚

## IDENTIFYING CANDIDATE ASSERTIONS

æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç›®æ ‡æ˜¯ç”Ÿæˆä¸€ç»„ candidate assertionsã€‚æˆ‘ä»¬å°†ä»‹ç» prompt deltas å¦‚ä½•ä¸ºå€™é€‰æ–­è¨€æä¾›ä¿¡æ¯ï¼Œå¹¶è§£é‡Šå¦‚ä½•ä»Žä¸­å¾—å‡ºå€™é€‰æ–­è¨€ã€‚

### Prompt Deltas

å•æ­¥ LLM æµæ°´çº¿ç”±ä¸€ä¸ªæç¤ºæ¨¡æ¿ P ç»„æˆï¼Œè¯¥æ¨¡æ¿é€šè¿‡å¯¹è¾“å…¥å…ƒç»„ ð‘¡ è¿›è¡Œæ ¼å¼åŒ–ï¼Œç”Ÿæˆä¸€ä¸ªæç¤º ð‘ï¼Œå¹¶è¿”å›žä¸€ä¸ªå“åº” ð‘Ÿã€‚P å¯ä»¥**æœ‰å¾ˆå¤šç‰ˆæœ¬**ï¼Œè¿™å–å†³äºŽå¼€å‘è€…å¦‚ä½•**è¿­ä»£ä»–ä»¬çš„ prompt template**ã€‚è®© $P_0$ è¡¨ç¤ºç©ºå­—ç¬¦ä¸²ï¼Œå³ç¬¬ 0 ä¸ªç‰ˆæœ¬ï¼Œè®© $P_i$ è¡¨ç¤ºæ¨¡æ¿çš„ç¬¬ i ä¸ªç‰ˆæœ¬ã€‚åœ¨ç¬¬ 1 èŠ‚çš„ç”µå½±æŽ¨èç¤ºä¾‹ä¸­ï¼Œå‡è®¾æœ‰ 7 ä¸ªç‰ˆæœ¬ï¼Œå…¶ä¸­ P7 å¦‚ä¸‹ï¼š

> Write a personalized note for
> why a user should watch {movie_name} given the following informa-
> tion about the user: {personal_info}. Ensure the recommendation
> note is concise, not exceeding 100 words. Mention the movieâ€™s genre
> and any shared cast members between the {movie_name} and other
> movies the user has watched. Mention any awards or critical acclaim
> received by {movie_name}. Do not mention anything related to the
> userâ€™s race, ethnicity, or any other sensitive attributes

æˆ‘ä»¬å°† prompt delta $Î”P_{ð‘–+1}$ å®šä¹‰ä¸º $P_i$ ä¸Ž $P_{i+1}$ ä¹‹é—´çš„å·®å€¼ã€‚å…·ä½“æ¥è¯´ï¼Œæç¤º Î”P æ˜¯ä¸€ç»„å¥å­ï¼Œå…¶ä¸­æ¯ä¸ªå¥å­éƒ½æ ‡è®°ä¸ºæ·»åŠ ï¼ˆå³ "+"ï¼‰æˆ–åˆ é™¤ï¼ˆå³"-"ï¼‰ã€‚ä¾‹å¦‚ï¼Œè¡¨ 1 æ˜¾ç¤ºäº†å¤šä¸ªç‰ˆæœ¬çš„ Î”Psã€‚Î”Pð‘– ä¸­çš„æ¯ä¸ªå¥å­éƒ½ç”±æ·»åŠ ï¼ˆå³ Pð‘– ä¸­çš„æ–°å¥å­ï¼ŒPð‘–-1 ä¸­ä¸å­˜åœ¨ï¼‰å’Œåˆ é™¤ï¼ˆå³ Pð‘–-1 ä¸­çš„å¥å­ï¼ŒPð‘– ä¸­ä¸å­˜åœ¨ï¼‰ç»„æˆã€‚å¯¹å¥å­çš„ä¿®æ”¹ç”±åˆ é™¤å’Œæ·»åŠ è¡¨ç¤º--ä¾‹å¦‚ï¼Œè¡¨ 1 ä¸­çš„ Î”P6 åŒ…å«äº†ä»Ž P5 ä¸­æ·»åŠ åˆ°å¥å­ä¸­çš„ä¸€äº›æ–°æŒ‡ä»¤ã€‚å¦‚è¡¨ 1 æœ€å³è¾¹ä¸€æ æ‰€ç¤ºï¼ŒÎ”Pð‘– ä¸­çš„æ¯ä¸€ä¸ªæ·»åŠ éƒ½è¡¨ç¤ºå¯èƒ½çš„æ–­è¨€æ ‡å‡†ã€‚

![](https://s2.loli.net/2024/03/03/PCyvBcO8q2YRGLn.png)

### Prompt Delta Analysis

æˆ‘ä»¬åˆ†æžäº†ä»Ž LangChain ç”¨æˆ·é‚£é‡Œæ”¶é›†åˆ°çš„ 19 ä¸ª LLM pipelineï¼Œæ¯ä¸ª pipeline ç”± 3 åˆ° 11 ä¸ªåŽ†å²æç¤ºæ¨¡æ¿ç‰ˆæœ¬ç»„æˆã€‚è¿™äº› pipeline æ¶µç›–å„ç§ä»»åŠ¡ï¼Œä»Žç”Ÿæˆå·¥ä½œæ€»ç»“åˆ°è‡ªå®šä¹‰é—®ç­”èŠå¤©æœºå™¨äººã€‚é™„å½• B ä¸­çš„è¡¨ 6 æ˜¾ç¤ºäº†è¿™äº› pipeline çš„æ‘˜è¦ï¼ŒåŒ…æ‹¬æ¯ä¸ª pipeline çš„æè¿°å’Œæç¤ºç‰ˆæœ¬çš„æ•°é‡ã€‚å¯¹äºŽæ¯ä¸ª pipeline ï¼Œæˆ‘ä»¬å°†æç¤ºç¬¦ï¼ˆå³ Î”Pð‘–ï¼‰åˆ†ä¸ºä¸åŒç±»åž‹--ä¾‹å¦‚ï¼ŒæŒ‡ç¤º LLM åœ¨æ¯ä¸ªå›žå¤ä¸­åŒ…å«ä¸€ä¸ªæ–°çŸ­è¯­ï¼ˆå³åŒ…å«ï¼‰ï¼Œæˆ–æŒ‡ç¤º LLM ä»¥æŸç§è¯­æ°”å›žå¤ï¼ˆå³å®šæ€§æ ‡å‡†ï¼‰ã€‚æˆ‘ä»¬å¯¹åˆ†ç±»è¿›è¡Œäº† 4 æ¬¡åå¤ä¿®æ”¹ï¼Œæœ€ç»ˆå½¢æˆäº†å›¾ 2 ä¸­çš„åˆ†ç±»æ³•ã€‚æç¤ºç‰ˆæœ¬çš„åˆ†ç±»æ³¨é‡Šæ•°æ®é›†å¯åœ¨ç½‘ä¸Šæ‰¾åˆ° 3ã€‚å¤§å¤šæ•°æç¤ºç¬¦éƒ½å±žäºŽæ•°æ®æ•´åˆï¼ˆå³æ·»åŠ å ä½å˜é‡ï¼‰å’Œå·¥ä½œæµç¨‹æè¿°ï¼ˆå³æ·»åŠ æŒ‡ç¤ºè®© LLM æ›´å‡†ç¡®åœ°æ‰§è¡Œä»»åŠ¡ï¼‰ã€‚åœ¨è¡¨ 2 ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å¼•è¨€ä¸­çš„ç”µå½±æŽ¨è pipeline ç¤ºä¾‹ï¼Œå±•ç¤ºäº†åˆ†ç±»æ³•ä¸­æ¯ä¸ªç±»åˆ«çš„æç¤ºåˆ†éš”ç¬¦ç¤ºä¾‹

![](https://s2.loli.net/2024/03/03/gXvSiduVAmU8Y6x.png)

å½“ä»Žè‡ªåŠ¨è¯†åˆ«çš„æç¤ºåˆ†éš”çº¿ä¸­å¾—å‡ºæ–­è¨€å€™é€‰é¡¹æ—¶ï¼Œæ–­è¨€è´¨é‡æ˜¾ç„¶å–å†³äºŽ**è¯†åˆ«ç±»åˆ«çš„å‡†ç¡®æ€§**ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç¡®è®¤äº† GPT-4 å¯¹æç¤ºåˆ†ç•Œç‚¹çš„æ­£ç¡®åˆ†ç±»ï¼ˆæˆªè‡³ 2023 å¹´ 10 æœˆï¼‰ã€‚æˆ‘ä»¬ä¸º 19 ä¸ª pipeline çš„æ‰€æœ‰æç¤ºç‰ˆæœ¬åˆ†é…äº†åŸºæœ¬çœŸå®žç±»åˆ«ï¼ŒGPT-4 çš„ F1 å¾—åˆ†ä¸º 0.8135ã€‚ç”¨äºŽä»Žæç¤ºåˆ†æ®µä¸­æå–ç±»åˆ«çš„æç¤ºè¯¦è§é™„å½• C

> ä»€ä¹ˆæ˜¯ F1 scoreï¼Ÿ åœ¨äºŒè¿›åˆ¶åˆ†ç±»å’Œä¿¡æ¯æ£€ç´¢ç³»ç»Ÿçš„ç»Ÿè®¡åˆ†æžä¸­ï¼ŒF-SCORE æˆ– F-MEASIE æ˜¯å¯¹é¢„æµ‹æ€§èƒ½çš„é‡åº¦ã€‚

### From Taxonomy to Assertions

åˆ©ç”¨æˆ‘ä»¬çš„åˆ†ç±»æ³•ï¼ŒSPADE ä½¿ç”¨ LLM ä¸º prompt deltas åˆ†ç±»å¹¶ç”Ÿæˆæ–­è¨€ï¼Œè¯¦è§é™„å½• Cã€‚å¯¹äºŽæ¯ä¸ª Î”Pð‘– ï¼ŒSPADE éƒ½ä¼šæç¤º LLM ä¸ºæ–­è¨€æå‡ºå°½å¯èƒ½å¤šçš„æ ‡å‡†ï¼Œæ¯ä¸ªæ ‡å‡†éƒ½ä¸Žåˆ†ç±»æ ‡å‡†çš„ç±»åˆ«ä¸€è‡´ (e.g., Figure 3) æ ‡å‡† Criterion è¢«å®½æ³›åœ°å®šä¹‰ä¸ºå¯¹ç¤ºä¾‹è¿›è¡Œæ“ä½œå¹¶è¯„ä¼°ä¸º "çœŸ "æˆ– "å‡ "çš„ä¸€äº›è‡ªç„¶è¯­è¨€è¡¨è¾¾å¼ï¼ˆä¾‹å¦‚ï¼Œ"check for conciseness"ï¼‰ã€‚Spade ä¼š**åˆ†æžæ¯ä¸ª Î”Pð‘–** è€Œä¸æ˜¯åªåˆ†æžæœ€åŽä¸€ä¸ªæç¤ºç‰ˆæœ¬ï¼ŒåŽŸå› æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼šå¼€å‘äººå‘˜é€šå¸¸ä¼šåˆ é™¤æç¤ºä¸­çš„æŒ‡ä»¤ä»¥é™ä½Žæˆæœ¬ï¼ŒåŒæ—¶æœŸæœ›èŽ·å¾—ç›¸åŒçš„è¡Œä¸º[35]ï¼›æç¤ºåŒ…å«å›ºæœ‰çš„æ­§ä¹‰ï¼Œå¹¶æš—ç¤ºäº†è¯„ä¼°æŸäº›æ ‡å‡†çš„å¤šç§æ–¹æ³•ï¼›å¦‚æžœåªåˆ†æžä¸€ä¸ªç‰ˆæœ¬ï¼Œå¤æ‚çš„æç¤ºå¯èƒ½ä¼š**å¯¼è‡´é—æ¼æ–­è¨€**ã€‚å› æ­¤ï¼Œ**åˆ†æžæ¯ä¸ª Î”Pð‘– ä¼šå¢žåŠ ç”Ÿæˆç›¸å…³æ–­è¨€çš„å¯èƒ½æ€§**

![](https://s2.loli.net/2024/03/03/VImk3LJovBM4uAf.png)

å¯¹äºŽæ¯ä¸ª deltaï¼Œspade éƒ½ä¼šæ”¶é›†å·²è¯†åˆ«çš„æ ‡å‡†ï¼Œå¹¶å†æ¬¡æç¤º LLM åˆ›å»º Python æ–­è¨€å‡½æ•°ã€‚åˆæˆå‡½æ•°å¯ä»¥ä½¿ç”¨å¤–éƒ¨ Python åº“ï¼Œä¹Ÿå¯ä»¥é’ˆå¯¹å¤æ‚çš„æ ‡å‡†å‘ LLM æå‡ºäºŒè¿›åˆ¶æŸ¥è¯¢ã€‚åœ¨å‡½æ•°åˆæˆæ—¶ï¼ŒLLM ä¼šè¢«æŒ‡ç¤ºï¼Œå¦‚æžœæ ‡å‡†æŒ‡å®šå¾—å¾ˆæ¨¡ç³Šæˆ–å¯ä»¥è§£é‡Šï¼Œä¾‹å¦‚ "check for conciseness"ï¼Œå®ƒå°±å¯ä»¥ç”Ÿæˆå¤šä¸ªå‡½æ•°ï¼Œæ¯ä¸ªå‡½æ•°éƒ½å¯¹æ ‡å‡†è¿›è¡Œè¯„ä¼°ã€‚åœ¨è¿™ä¸ªç®€æ´æ€§ç¤ºä¾‹ä¸­ï¼ŒLLM å¯ä»¥è¿”å›žå¤šä¸ªå‡½æ•°--ä¸€ä¸ªå°†å›žå¤åˆ†æˆå¥å­å¹¶ç¡®ä¿ä¸è¶…è¿‡ï¼ˆä¾‹å¦‚ï¼‰3 ä¸ªå¥å­çš„å‡½æ•°ï¼Œä¸€ä¸ªå°†å›žå¤åˆ†æˆå•è¯å¹¶ç¡®ä¿ä¸è¶…è¿‡ï¼ˆä¾‹å¦‚ï¼‰25 ä¸ªå•è¯çš„å‡½æ•°ï¼Œæˆ–è€…ä¸€ä¸ªå°†å›žå¤å‘é€ç»™ LLM å¹¶è¯¢é—®å›žå¤æ˜¯å¦ç®€æ´çš„å‡½æ•°ã€‚è¿™ä¸€æ­¥éª¤çš„æ€»ä½“ç»“æžœæ˜¯å€™é€‰å‡½æ•°çš„å¤šé›†åˆ ð¹ = {ð‘“1, ..., ð‘“ð‘š} ã€‚

æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨äº†ä¸¤æ­¥æµç¨‹ï¼Œå› ä¸ºäº‹å®žè¯æ˜Žï¼Œ**å°†ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªæ­¥éª¤å¯ä»¥æé«˜ LLM çš„å‡†ç¡®æ€§** [21, 53, 55]ã€‚ä¸è¿‡ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œéšç€ LLM æ—¥æ–°æœˆå¼‚çš„å‘å±•ï¼Œ**ä¸€æ­¥å¼æµç¨‹å¯èƒ½å·²ç»å¯è¡Œ**ã€‚æ­¤å¤–ï¼Œè™½ç„¶æˆ‘ä»¬çš„**åˆ†ç±»æ³•**çŽ°åœ¨å¯ä»¥æŒ‡å¯¼ LLM ç”Ÿæˆæ–­è¨€ï¼Œä½†æœªæ¥çš„ LLM å¯èƒ½ä¼šé€šè¿‡**äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ æ¥éšå¼åœ°å­¦ä¹ è¿™äº›ç±»åˆ«**[12]ã€‚ä¸è¿‡ï¼Œäº†è§£ä¸Žå€™é€‰æ–­è¨€ç›¸å…³çš„åŸºäºŽåˆ†ç±»å­¦çš„ç±»åˆ«å¯èƒ½æœ‰åŠ©äºŽè¿‡æ»¤å®ƒä»¬

> Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows. arXiv preprint arXiv:2312.11681 (2023)
>
> Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems
>
> ä»»åŠ¡åˆ†è§£ä¸ºä»€ä¹ˆå¯ä»¥æé«˜ LLM çš„å‡†ç¡®æ€§ï¼Ÿè€Œä¸”çŽ°åœ¨ ChatGPT å°±æ˜¯ç”¨çš„ Human Feedback RL æ¥å¢žå¼ºçš„ Deep reinforcement learning from human preferences

### LangChain Deployment

> æ¯”è¾ƒäº†æ—©æœŸç‰ˆæœ¬å’ŒåŽæœŸçš„åŒºåˆ«ï¼Œå¹äº†ä¸€ä¸‹è‡ªå·±ç”Ÿæˆçš„æ–­è¨€æœ‰å¤šä¹ˆå¥½ï¼Œæ¶µç›–äº†å¤šå°‘ä¸ªé¢†åŸŸï¼Œè¾¾åˆ°äº† "perfect"
>
> æåˆ°äº†ä¸€ä¸ªæ€»ç»“æ–‡ç« çš„ä¾‹å­ï¼Œå…·æœ‰ 14 ä¸ª prompt ç‰ˆæœ¬ï¼Œå¯¹ä»– SPADE åŽï¼Œå¯ä»¥æœ‰ä¸€äº›æ–­è¨€ï¼Œå¿…é¡»è¦æœ‰ä¸€äº›å…³é”®è¯ç­‰ç­‰
>
> ä½†è¿™äº›æ–­è¨€å¹¶ä¸æ˜¯æ­£åˆ™åŒ¹é…ï¼Œè€Œæ˜¯å­—ç¬¦ä¸²åŒ¹é…ï¼Œæˆ‘è§‰å¾—ä¸å¤ªåˆç†ã€‚
>
> æ–‡ä¸­ä¹Ÿæåˆ°è¯´è®¸å¤šæ–­è¨€å¯èƒ½æ˜¯ä¸æ­£ç¡®çš„ï¼Œæ€Žä¹ˆçŸ¥é“æ–­è¨€æ˜¯æ­£ç¡®çš„å‘¢ï¼Ÿæœ¬æ–‡çš„å®žéªŒå¯èƒ½ä¹Ÿä¸å¤Ÿï¼ŒäºŽæ˜¯é‡‡ç”¨äº†è‡ªåŠ¨åŒ– filtering

## FILTERING CANDIDATE ASSERTIONS

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è§£å†³äº†ç¬¬ 2.4 èŠ‚ä¸­ç¡®å®šçš„**å†—ä½™å’Œä¸æ­£ç¡®æ–­è¨€**çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰å¤§é‡ prompt ç‰ˆæœ¬çš„ pipeline ä¸­ã€‚ è¿‡æ»¤æ­¤å€™é€‰é›†ä¸ä»…å¯ä»¥æé«˜éƒ¨ç½²æ–­è¨€ä»¥åœ¨ç”Ÿäº§ä¸­è¿è¡Œæ—¶çš„æ•ˆçŽ‡ï¼Œè€Œä¸”è¿˜å¯ä»¥å‡å°‘å¼€å‘äººå‘˜çš„è®¤çŸ¥å¼€é”€

### Definitions

å°† ð‘’ð‘– è§†ä¸º LLM pipeline åœ¨æŸäº›è¾“å…¥ä¸Šçš„ç«¯åˆ°ç«¯æ‰§è¡Œï¼ˆå³è¿è¡Œï¼‰çš„ç¤ºä¾‹ã€‚ ä»¤ ð¸ ä¸ºæ‰€æœ‰æ­¤ç±»ç¤ºä¾‹è¿è¡Œçš„é›†åˆï¼ˆè¯¥é›†åˆæœªé¢„å…ˆæä¾›ï¼Œæˆ‘ä»¬å°†å¾ˆå¿«å¤„ç†ï¼‰ã€‚ æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ–­è¨€å‡½æ•° ð‘“ : ð¸ â†’ {0,1}ï¼Œå…¶ä¸­ 1 è¡¨ç¤ºæˆåŠŸï¼Œ0 è¡¨ç¤ºå¤±è´¥ã€‚ ä»¤ ð¹â€² ={ð‘“1, ð‘“2, . ã€‚ ., ð‘“ð‘˜} æ˜¯ä¸€ç»„ ð‘˜ æ–­è¨€ã€‚ å½“ä¸”ä»…å½“ä¸€ä¸ªä¾‹å­ ð‘’ð‘– **æ»¡è¶³ ð¹' ä¸­çš„æ‰€æœ‰æ–­è¨€**æ—¶ï¼Œè¯¥é›†åˆæ‰è®¤ä¸ºå®ƒæ˜¯æˆåŠŸçš„ã€‚ å…·ä½“æ¥è¯´

> ä¸€äº›æ•°å­¦å®šä¹‰ï¼Œå®šä¹‰äº† Coverage å’Œ False Failure Rate

### Coverage Problem Formulation

> ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€å°çš„é›†åˆ minimal set of assertions æ»¡è¶³æ‰€æœ‰ä¾‹å­ï¼Ÿ
>
> æ‰¾åˆ°ä¸€ä¸ª Coverage(ð¹â€²) â‰¥ð›¼, FFR(ð¹â€²) â‰¤ðœ
>
> æ‰¾åˆ°é™åˆ¶ï¼Œå°±å˜æˆäº†ä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œé›†åˆè¦†ç›–é—®é¢˜

æˆ‘ä»¬å°†æ­¤ ILP çš„è§£å†³æ–¹æ¡ˆç§°ä¸º $spade_{cov}$ã€‚ ç®€å•åœ°è¯´ï¼Œå¯¹äºŽ ðœ =0 å’Œ ð›¼ =1ï¼Œè¿™ä¸ªé—®é¢˜æ˜¯ NP-hard çš„ï¼Œé€šè¿‡ç®€å•åœ°ä»Žé›†åˆè¦†ç›–å½’çº¦ï¼Œå¹¶ä¸”æ˜¯ NP é—®é¢˜ï¼Œå› ä¸ºå®ƒå¯ä»¥ç”¨ ILP å½¢å¼è¡¨ç¤º

### Subsumption Problem Formulation

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬**å‡è®¾å¼€å‘äººå‘˜æ„¿æ„æä¾›ä¸€ç»„å…¨é¢çš„æ ‡è®°ç¤ºä¾‹è¿è¡Œ** ð¸â€²ï¼Œåœ¨å¼€å‘äººå‘˜ä¸æ„¿æ„è¿™æ ·åšçš„è®¾ç½®ä¸­ï¼Œå¹¶ä¸” ð¸â€²ä¸åŒ…æ‹¬ ð¸ ä¸­çš„æ‰€æœ‰æ•…éšœç±»åž‹ï¼Œspade_cov å¯èƒ½ä¼š å¿½ç•¥ ð¹ ä¸­çš„æœ‰ç”¨æ–­è¨€ï¼Œè¿™äº›æ–­è¨€åªèƒ½æ•èŽ· ð¸ \ð¸â€² ä¸­çš„å¤±è´¥â€”â€”å¦‚ç¬¬ 4 èŠ‚ä¸­çš„ç»éªŒæ‰€ç¤ºã€‚æˆ‘ä»¬æœ€åˆè€ƒè™‘ä½¿ç”¨ä¸»åŠ¨å­¦ä¹  [6] ä¸ºæ¯ä¸ªæ–­è¨€é‡‡æ ·æ›´å¤šçš„ LLM å“åº”ï¼Œå¹¶ä½¿ç”¨å¼±ç›‘ç£æ¥æ ‡è®°å“åº” [36 ]ã€‚ ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¯¹äºŽæœ€å…ˆè¿›çš„ LLM æ¥è¯´æˆæœ¬é«˜æ˜‚ï¼Œå¹¶ä¸”**éœ€è¦å¤§é‡çš„æ‰‹åŠ¨å·¥ä½œæ¥å¹³è¡¡æ¯ä¸ªæ–­è¨€çš„å¤±è´¥å’ŒæˆåŠŸç¤ºä¾‹**ï¼Œç¡®ä¿æœ‰æ„ä¹‰çš„ FFR å¹¶é¿å…ç”±äºŽä»£è¡¨æ€§ä¸è¶³çš„æ•…éšœç±»åž‹è€ŒæŽ’é™¤æ–­è¨€ã€‚ å¯¹äºŽè¿™ç§è®¾ç½®ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†åŒ…å«ã€‚ å‡è®¾æ‰€æœ‰å€™é€‰æ–­è¨€å‡½æ•°æ¶µç›–å°½å¯èƒ½å¤šçš„æ•…éšœæ¨¡å¼ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€‰æ‹© ð¹â€² âŠ† ð¹ï¼Œä½¿å¾— ð¹ \ð¹â€² ä¸­çš„æ–­è¨€åŒ…å«åœ¨ ð¹â€² ä¸­ã€‚ å½¢å¼ä¸Šï¼Œå¦‚æžœ ð‘† ä¸­å‡½æ•°çš„åˆå–é€»è¾‘ä¸Šæ„å‘³ç€ ð‘† å’Œ ð‘“ ä¸­å‡½æ•°çš„åˆå–ï¼Œåˆ™ä¸€ç»„å‡½æ•° ð‘† åŒ…å«æŸä¸ªå‡½æ•° ð‘“ ã€‚

> å¤ªå¤šå®šä¹‰äº†ï¼Œå¯èƒ½ä¸»è¦æ˜¯åœ¨è§£å†³è¿™ä¸ªé›†åˆè¦†ç›–å§

## EVALUATION

æˆ‘ä»¬é¦–å…ˆè®¨è®º LLM pipelines å’Œæ•°æ®é›†ï¼ˆå³ ð¸â€²ï¼‰ï¼› ç„¶åŽï¼Œæˆ‘ä»¬è®¨è®ºæ–¹æ³•å’ŒæŒ‡æ ‡å¹¶å±•ç¤ºæˆ‘ä»¬çš„ç»“æžœã€‚ å®žéªŒä»£ç ã€æ•°æ®é›†å’Œ LLM å“åº”æ‰˜ç®¡åœ¨ GitHub ä¸Š

### Pipeline and Dataset Descriptions

æˆ‘ä»¬å¯¹ 9 ä¸ª LLM pipeline è¿›è¡Œäº†è¯„ä¼°ï¼Œå…¶ä¸­ 8 ä¸ªæ¥è‡ª LangChain Hubï¼ˆLLM pipeline çš„å¼€æºé›†åˆï¼‰ï¼Œä»¥åŠ 1 ä¸ªä¸“æœ‰ pipeline ã€‚ å…­ä¸ª LangChain Hub pipeline å¸®åŠ©å¼€å‘äº† prompt delta taxonomyï¼ˆç¬¬ 2.2 èŠ‚ï¼‰ï¼Œä½†åœ¨åˆ›å»ºåˆ†ç±»æ³•åŽï¼Œä»Ž spade çš„ Streamlit éƒ¨ç½²ï¼ˆç¬¬ 2.4 èŠ‚ï¼‰æ·»åŠ äº†ä¸¤æ¡ pipeline ã€‚ ä¸“æœ‰ pipeline æ˜¯ fashion pipelineï¼Œå®ƒä¸ºæ´»åŠ¨æä¾›æœè£…å»ºè®®ã€‚ ä¹‹æ‰€ä»¥åŒ…å«æ­¤ pipeline ï¼Œæ˜¯å› ä¸ºå®ƒä½¿ç”¨äº† LLM åŸ¹è®­ä¸­æœªåŒ…å«çš„æ•°æ®åŠå…¶å®žé™…éƒ¨ç½²ï¼Œå±•ç¤ºäº† Spade çš„ real-world æ€§ã€‚ è™½ç„¶æˆ‘ä»¬ä½¿ç”¨çœŸå®žçš„ç”¨æˆ·æç¤ºæ¨¡æ¿å’ŒåŽ†å²è®°å½•ï¼ˆ3 åˆ° 16 ä¸ªæç¤ºç‰ˆæœ¬ä¹‹é—´ï¼‰ï¼Œä½†æˆ‘ä»¬æž„å»ºäº†è‡ªå·±çš„ä¸€ç»„ç¤ºä¾‹æç¤º-å“åº”å¯¹å’Œæ ‡ç­¾ (ð¸â€²) è¿›è¡Œæµ‹è¯•ã€‚ LangChain Hub pipeline çš„ä¸¤ä¸ªæ•°æ®é›†æ¥è‡ª Kaggleï¼Œè€Œå…¶ä»–æ•°æ®é›†æ˜¯ä½¿ç”¨ Chat GPT Proï¼ˆåŸºäºŽ GPT-4ï¼‰ç»¼åˆç”Ÿæˆçš„ã€‚ ä¾‹å¦‚ï¼Œå¯¹äºŽä½¿ç”¨ LLM å®¡æŸ¥æ‹‰å–è¯·æ±‚çš„ codereviews pipeline ï¼Œæˆ‘ä»¬è¦æ±‚ Chat GPT ç”Ÿæˆæ¶µç›–å„ç§ç¼–ç¨‹è¯­è¨€ã€åº”ç”¨ç¨‹åºç±»åž‹å’Œå·®å¼‚å¤§å°çš„å ä½ç¬¦å€¼ã€‚ æˆ‘ä»¬å¯¹ 8 ä¸ª LangChain pipeline çš„ LLM å›žå¤è¿›è¡Œäº†æ ‡è®°ï¼Œä»¥è¯„ä¼°ä»–ä»¬æ˜¯å¦ç¬¦åˆæç¤ºè¯´æ˜Žã€‚ å“åº”åˆ†ä¸º GPT-3.5-Turbo å’Œ GPT-4ã€‚ å¯¹äºŽ fashion pipeline ï¼Œæ ‡ç­¾æ˜¯ç”±å¼€å‘äººå‘˜åœ¨ç›¸åº”çš„å¯åŠ¨æ—¶å®Œæˆçš„ã€‚ è¡¨ 3 æä¾›äº†æ¯ä¸ª LLM æµç¨‹å’Œæ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯ã€‚ æˆ‘ä»¬å·²ç»å¼€æºäº† LangChain Hub 8 ä¸ª pipeline çš„æ‰€æœ‰æ•°æ®

### Method Comparison and Metrics

å’Œä¹‹å‰ä¸€æ ·ï¼Œä»¤ ð¸â€² ä¸ºç¤ºä¾‹æç¤º-å“åº”å¯¹çš„æ•°æ®é›†ï¼Œä»¥åŠå“åº”æ˜¯å¥½ï¼ˆå³ 1ï¼‰è¿˜æ˜¯åï¼ˆå³ 0ï¼‰çš„ç›¸åº”æ ‡ç­¾ã€‚ ä»¤ ðœ ä¸º FFR é˜ˆå€¼ï¼Œð¹ ä¸º SPADE ç¬¬ä¸€æ­¥äº§ç”Ÿçš„å€™é€‰æ–­è¨€é›†ï¼ˆç¬¬ 2 èŠ‚ï¼‰ã€‚ å¦‚æžœå€™é€‰å‡½æ•° ð‘“ å¯¼è‡´æŸäº›ç¤ºä¾‹ ð‘’ å‡ºçŽ°è¿è¡Œæ—¶é”™è¯¯ï¼Œæˆ‘ä»¬è¡¨ç¤º ð‘“ (ð‘’) =0ï¼ˆå³å¤±è´¥ï¼‰ã€‚ æˆ‘ä»¬æ‰€æœ‰çš„ä»£ç éƒ½æ˜¯ç”¨ Python ç¼–å†™çš„ï¼Œä½¿ç”¨ PuLP Python åŒ…æ¥å¯»æ‰¾ ILP çš„è§£å†³æ–¹æ¡ˆã€‚ æˆ‘ä»¬ä½¿ç”¨é»˜è®¤çš„ PuLP é…ç½®ï¼Œå®ƒä½¿ç”¨ CBC æ±‚è§£å™¨ [18]ã€‚ æˆ‘ä»¬è¯„ä¼°äº† spade çš„ä¸‰ä¸ªç‰ˆæœ¬ï¼š â€¢ $spade_base$ é€‰æ‹© ð¹ ä¸­çš„æ‰€æœ‰å‡½æ•° ð‘“ï¼Œå…¶ä¸­ FFR ({ð‘“ }) â‰¤ðœ â€¢ spade_cov æ˜¯ç¬¬ 3.2 èŠ‚ä¸­å®šä¹‰çš„ ILP çš„è§£ â€¢ spade_sub æ˜¯ç¬¬ 3.3.1 èŠ‚ä¸­å®šä¹‰çš„ ILP çš„è§£ è®© ð¹â€² ä»£è¡¨ä»»ä½•ç‰ˆæœ¬çš„ spade æ‰€é€‰æ‹©çš„æ–­è¨€é›†åˆã€‚ æˆ‘ä»¬æµ‹é‡å››ä¸ªæŒ‡æ ‡ï¼š

(1) æ‰€é€‰æ–­è¨€çš„åˆ†æ•°ï¼ˆå³ |ð¹â€²|/|ð¹|ï¼‰

(2) æŽ’é™¤çš„éžåŒ…å«å‡½æ•°çš„åˆ†æ•°ï¼ˆå³ |ðº|/|ð¹|ï¼Œå…¶ä¸­ ðº ={ð‘” |ð‘” Îµð¹ \ð¹â€² å’Œ ð¹â€² Ì¸=â‡’ ð‘”})

(3) é”™è¯¯å¤±è´¥çŽ‡ï¼ˆå®šä¹‰ 3.2ï¼‰

(4) ð¸â€² çš„è¦†ç›–çŽ‡ï¼ˆå®šä¹‰ 3.1ï¼‰

æ­¤å¤–ï¼Œspade_sub æˆåŠŸçš„ä¸€ä¸ªé‡è¦æ–¹é¢æ˜¯åŒ…å«çš„æœ‰æ•ˆæ€§ æ‰€æœ‰æ–­è¨€å¯¹ä¹‹é—´çš„è¯„ä¼°ã€‚ ç”±äºŽæˆ‘ä»¬**æ²¡æœ‰åŒ…å«çš„åŸºæœ¬äº‹å®ž**ï¼Œå› æ­¤æˆ‘ä»¬å…³æ³¨**ç²¾åº¦**ï¼Œè®¡ç®—ä¸ºæ­£ç¡®è¯†åˆ«çš„åŒ…å«å¯¹åœ¨ LLM è¯†åˆ«çš„æ‰€æœ‰åŒ…å«å¯¹ä¸­çš„æ¯”ä¾‹ã€‚ **æˆ‘ä»¬ä¸è¯„ä¼°å¬å›žçŽ‡**ï¼ˆGPT-4 æ˜¯å¦è¯†åˆ«äº†æ¯ä¸€ä¸ªå¯èƒ½çš„åŒ…å«ï¼‰ï¼Œå› ä¸ºä¸ºæ¯ä¸ªç®¡é“æ ‡è®°å¯èƒ½æ•°ä¸‡ä¸ªæ–­è¨€å¯¹æ˜¯ä¸åˆ‡å®žé™…çš„ã€‚ æ­¤å¤–ï¼Œ**ç²¾ç¡®åº¦**æ¯”å¬å›žçŽ‡æˆ–å‡†ç¡®æ€§æ›´é‡è¦ï¼Œå› ä¸ºå³ä½¿è¯†åˆ«ä¸€äº›åŒ…å«ï¼Œspade_sub ä¹Ÿèƒ½ç”¨æ¯” $spade_base$ æ›´å°‘çš„é€‰å®šæ–­è¨€æ¥å®žçŽ°è§£å†³æ–¹æ¡ˆã€‚

> è¿™é‡Œè¯„ä¼°ç²¾ç¡®çŽ‡ï¼Œä½†å´å¿½ç•¥å¬å›žçŽ‡ï¼Œæ„Ÿè§‰æ˜¯è®ºæ–‡ä¸å¤Ÿå…¨é¢çš„åœ°æ–¹ã€‚
>
> ç²¾ç¡®çŽ‡ï¼šTP/ (TP + FP)ï¼Œæˆ‘è§‰å¾—æœ‰æ•…éšœä¸­çš„çœŸæ•…éšœ / ï¼ˆæˆ‘è§‰å¾—æœ‰æ•…éšœä¸”çœŸæ•…éšœ + æˆ‘è§‰å¾—æœ‰æ•…éšœä½†æ²¡æ•…éšœï¼‰
>
> å¬å›žçŽ‡ï¼šTP / (TP + FN), æˆ‘è§‰å¾—æœ‰æ•…éšœä¸­çš„çœŸæ•…éšœ / ï¼ˆæˆ‘è§‰å¾—æœ‰æ•…éšœä¸”çœŸæ•…éšœ + æˆ‘è§‰å¾—æ²¡æ•…éšœä½†çœŸæ•…éšœï¼‰
>
> èƒ½å¦ç†è§£ä¸ºï¼Œç²¾ç¡®çŽ‡åŒºåˆ†çœŸå‡æ­£ç¡®ï¼Œå¬å›žçŽ‡é’ˆå¯¹æ ·æœ¬ä¸­æœ‰å¤šå°‘æ­£ç¡®çš„æ˜¯ä½ ç»™å‡ºæ¥çš„ã€‚æ‰€ä»¥ä¸€èˆ¬ä¸¤è€…éƒ½è¦ä¸€èµ·è€ƒè™‘ï¼Ÿ

### Results and Discussion

ä½¿ç”¨ GPT-4 è¯„ä¼°æ‰€æœ‰ pipeline çš„å½’å¹¶ç»“æžœï¼Œ**å¹³å‡ç²¾åº¦ä¸º 0.82**ï¼Œå¦‚è¡¨ 5 æ‰€ç¤ºï¼Œè¯å®žäº†å…¶æœ‰æ•ˆæ€§ã€‚ ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰ç®¡é“çš„è¦†ç›–çŽ‡å’Œ FFR é˜ˆå€¼è®¾ç½®ä¸ºç›¸åŒï¼ˆð›¼ =0.6ï¼Œðœ =0.25ï¼‰ã€‚ æˆ‘ä»¬åœ¨è¡¨ 4 ä¸­æŠ¥å‘Šäº†ä¸‰ç§æ–¹æ³•çš„ç»“æžœã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ codereviews ç®¡é“ï¼Œå®ƒä½¿ç”¨ LLM æ¥å®¡æŸ¥ä»»ä½•ä»£ç å­˜å‚¨åº“çš„æ‹‰å–è¯·æ±‚ã€‚ è¿™é‡Œï¼Œ $spade_base$ é€‰æ‹© 20 ä¸ªæ–­è¨€ï¼Œ $spade_base$ é€‰æ‹© 2 ä¸ªæ–­è¨€ï¼Œ spade_sub é€‰æ‹© 15 ä¸ªæ–­è¨€ã€‚ é€šè¿‡é€‰æ‹©æ›´å¤šå‡½æ•°ï¼Œspade_sub å¯ç¡®ä¿åŒ…å«æ‰€æœ‰æœªåŒ…å«çš„å‡½æ•°ã€‚ æ‰€æœ‰ä¸‰ç§æ–¹æ³•éƒ½éµå®ˆ ð¸â€² è¦†ç›–çº¦æŸï¼Œä½† $spade_base$ åœ¨ 9 ä¸ªç®¡é“ä¸­æœ‰ 4 ä¸ªè¿åäº† FFR çº¦æŸã€‚ å¹³å‡è€Œè¨€ï¼Œä¸Ž $spade_base$ ç›¸æ¯”ï¼Œspade_sub é€‰æ‹©çš„æ–­è¨€æ•°é‡å‡å°‘äº†çº¦ 14%ï¼Œå¹¶ä¸” FFR æ˜¾ç€é™ä½Žï¼Œç›¸å¯¹äºŽ $spade_base$ å‡å°‘äº†çº¦ 21%ã€‚ spade_cov å¹³å‡æŽ’é™¤äº† 44% æœªåŒ…å«åœ¨ ð¹â€² ä¸­çš„å‡½æ•°ã€‚ æˆ‘ä»¬éšåŽè®¨è®ºä¸åŒ spade å®žçŽ°ä¹‹é—´çš„æƒè¡¡

> ç»“æžœå’Œä¾‹å­éƒ½æ˜¾ç¤ºäº†æ¯”è¾ƒé«˜çš„ precisionï¼Œè€Œä¸”ç”¨çš„æ˜¯ GPT-4
>
> å…¶ä¸­ code review pipeline çš„ä¸€äº› assertion ä¼šå›žåŽ»è°ƒç”¨ LLMï¼Œè¯¢é—®æ˜¯å¦åŒ…å«ä»£ç ä¿®æ”¹çš„å»ºè®®ï¼Œreview æ˜¯å¦ç²¾ç®€ï¼Œæ˜¯å¦èšç„¦äºŽè¯¥ PR
>
> å‰©ä¸‹çš„æ²¡ä»”ç»†çœ‹ï¼Œå¾ˆå¤šç»“æžœå¹¶ä¸æ˜¯å¾ˆä»¤äººä¿¡æœï¼Œå°¤å…¶æ˜¯å¯¹ä¸‰ä¸ªä¸åŒçš„ SPADE (base é€‰æ‹©æ‰€æœ‰çš„ fï¼Œcov é€‰æ‹©æœ€å°çš„é›†åˆï¼Œsub æ˜¯ Subsumption Constraints é™åˆ¶çš„)

ä¸åŒç‰ˆæœ¬ SPADE çš„ç»“æžœï¼Œð›¼ =0.6 å’Œ ðœ =0.25ã€‚ å‹¾å·å’Œ x æ ‡è®°è¡¨ç¤ºæ˜¯å¦æ»¡è¶³ ð›¼ å’Œ ðœ çº¦æŸã€‚ æ¯ä¸ªæ¡ç›®éƒ½æ˜¯è¯¥ç®¡é“çš„å€™é€‰æ–­è¨€æ€»æ•°çš„ä¸€éƒ¨åˆ†ï¼ˆæ‹¬å·ä¸­æ˜¯ç»å¯¹æ•°é‡ï¼‰ã€‚ spade_cov æ€»ä½“ä¸Šé€‰æ‹©æœ€å°‘çš„æ–­è¨€ã€‚ spade_sub åœ¨ä¼˜åŒ–åŒ…å«æ—¶é€‰æ‹©æœ€å°‘çš„æ–­è¨€

ðœ¶ and ð‰ Threshold Sensitivityï¼šSpade ä¸­ ILP æ±‚è§£å™¨çš„è§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§å–å†³äºŽæ‰€é€‰çš„ ð›¼ å’Œ ðœ é˜ˆå€¼ã€‚ å¦‚æžœæ‰¾ä¸åˆ°å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œå¼€å‘äººå‘˜å¯èƒ½éœ€è¦ä»¥äºŒåˆ†æœç´¢çš„æ–¹å¼è°ƒæ•´è¿™äº›å€¼ã€‚ åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæ‰€æœ‰ 9 ä¸ª LLM ç®¡é“éƒ½äº§ç”Ÿäº† ð›¼ = 0.6 å’Œ ðœ = 0.25 çš„å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚ ç„¶è€Œï¼Œð¸â€² çš„å°å°ºå¯¸ä½¿å¾— spade_cov å¯¹ ð›¼ ç‰¹åˆ«æ•æ„Ÿã€‚ åœ¨ç®¡é“ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ° 1 åˆ° 5 ä¸ªæ–­è¨€è¦†ç›–äº† 60% çš„å¤±è´¥ã€‚ ä¾‹å¦‚ï¼Œspade_cov åªä¸ºç”µå­é‚®ä»¶ç®¡é“é€‰æ‹©äº†ä¸€ä¸ªæ–­è¨€

FFR Tradeoffs: è€ƒè™‘åˆ°å¯¹äºŽä¸‰ä¸ª LLM ç®¡é“ï¼Œä¸º spade_base å’Œ spade_sub é€‰æ‹©çš„å‡½æ•°æ¯”ä¾‹ä¹‹é—´çš„å·®å¼‚å°äºŽ 10%ï¼Œäººä»¬å¯èƒ½æƒ³çŸ¥é“ spade_sub çš„å¤æ‚æ€§æ˜¯å¦å€¼å¾—ã€‚ spade_sub é€šå¸¸æ›´å¯å–ï¼Œå› ä¸º spade_base æ— æ³•å§‹ç»ˆæ»¡è¶³ FFR é˜ˆå€¼ ðœã€‚ æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œéšç€æç¤ºç‰ˆæœ¬çš„å¢žåŠ ï¼Œæ–­è¨€çš„æ•°é‡ä¹Ÿä¼šå¢žåŠ ï¼Œä»Žè€Œå¯¹ spade_base äº§ç”Ÿä¸åˆ©å½±å“ã€‚ ä¸€ç»„çš„æœ€åæƒ…å†µ FFR æ˜¯å„ä¸ª FFR çš„æ€»å’Œï¼Œå¦‚å…¬å¼ (2) æ‰€ç¤ºã€‚ å› æ­¤ï¼Œåœ¨å­˜åœ¨å¤§é‡ç‹¬ç«‹æ–­è¨€çš„æƒ…å†µä¸‹ï¼Œæ€» FFR å¾ˆå¯èƒ½ä¼šè¶…è¿‡é˜ˆå€¼ã€‚è¿™ä¸ªé—®é¢˜åœ¨ fashion å’Œ lecturesummaries ç®¡é“ä¸­å¾ˆæ˜Žæ˜¾ï¼Œå°½ç®¡ 67 å’Œ 32 ä¸ªæ–­è¨€ä¸­çš„æ¯ä¸€ä¸ªéƒ½å•ç‹¬æ»¡è¶³ FFR çº¦æŸï¼Œä½† spade_base çš„æ€» FFR åˆ†åˆ«è¾¾åˆ° 0.88 å’Œ 0.53ã€‚ å®žé™…ä¸Šï¼Œå¦‚æžœå°† spade éƒ¨ç½²åœ¨äº¤äº’å¼ç³»ç»Ÿä¸­ï¼Œå…¶ä¸­ spade å¯ä»¥å®žæ—¶è§‚å¯Ÿæ¯ä¸ª LLM è°ƒç”¨ï¼ˆä¾‹å¦‚ï¼Œä½œä¸º OpenAI API çš„åŒ…è£…å™¨ï¼‰ï¼Œåˆ™å¤§é‡çš„æç¤ºç‰ˆæœ¬è¿›ä¸€æ­¥éœ€è¦åŸºäºŽæ•´ä½“ FFR è¿‡æ»¤æ–­è¨€ ã€‚ è¿™å¼ºè°ƒäº†å¯¹æ›´å¤æ‚çš„ spade_cov æˆ– spade_sub æ–¹æ³•çš„éœ€è¦

### Limitations and Future Work

Improving Quality of LLMs: è™½ç„¶ LLMï¼ˆå°é—­å¼å’Œå¼€æºï¼‰æ­£åœ¨è¿…é€Ÿæ”¹è¿›ï¼Œå¹¶ä¸”æˆ‘ä»¬æ²¡æœ‰æ˜Žç¡®ç ”ç©¶ spade çš„ prompt engineering strategiesï¼Œä½†è¡¥å……çš„ç ”ç©¶æƒ³æ³•æ˜¯**æŽ¢ç´¢æ­¤ç±»ç­–ç•¥æˆ–å¾®è°ƒå°åž‹å¼€æºæ¨¡åž‹ä»¥ç”Ÿæˆæ–­è¨€**ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºå°† subsumption ä½œä¸ºè¦†ç›–èŒƒå›´ä»£ç†ï¼Œä½†æ²¡æœ‰æŽ¢ç´¢ prompt å·¥ç¨‹ç”šè‡³éž LLM ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼Œæ–­è¨€æ¥æºï¼‰æ¥è¯„ä¼°åŒ…å«ã€‚ å°½ç®¡ LLM å–å¾—äº†è¿›æ­¥ï¼Œä½† SPADE çš„è¿‡æ»¤é˜¶æ®µå¯¹äºŽå‡å°‘å†—ä½™å’Œç¡®ä¿å‡†ç¡®æ€§ä»ç„¶è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯å› ä¸ºæ–­è¨€å¯èƒ½æ¶‰åŠ LLMã€‚

Collecting Labeled Examples: èŽ·å–æ ‡è®°æ•°æ®ï¼ˆð¸â€²ï¼‰å¾ˆå›°éš¾ã€‚ æˆ‘ä»¬çš„å¤§å¤šæ•°æ•°æ®é›†çš„æç¤ºç‰ˆæœ¬å¾ˆå°‘ï¼ˆåªæœ‰æäº¤ç»™ LangChain Hub çš„ç‰ˆæœ¬ï¼‰ï¼Œä½†å®žé™…ä¸Šï¼Œå¼€å‘äººå‘˜å¯èƒ½ä¼šå¯¹å…¶æç¤ºè¿›è¡Œæ•°åæˆ–æ•°ç™¾æ¬¡è¿­ä»£ã€‚ æœªæ¥çš„å·¥ä½œå¯èƒ½æ¶‰åŠé€šè¿‡ LLM API åŒ…è£…å™¨è¿›è¡Œè¢«åŠ¨ç¤ºä¾‹æ”¶é›†æˆ–æ”¶é›†å¼€å‘äººå‘˜å¯¹æ–­è¨€çš„åé¦ˆã€‚ å¯¹ä¸åŒç±»åž‹çš„æ–­è¨€è¿›è¡Œä¼˜å…ˆçº§æŽ’åºå¹¶åœ¨ spade ä¸­å°†è¿™äº›ä¼˜å…ˆçº§å½¢å¼åŒ–æ˜¯å¦ä¸€ä¸ªéœ€è¦æŽ¢ç´¢çš„é¢†åŸŸã€‚ æ­¤å¤–ï¼Œåœ¨æœ‰é™çš„ ð¸â€² ä¸‹è¯„ä¼° FFR ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå¹¶æŽ¢ç´¢åœ¨ç¼ºä¹å¤§åž‹æ ‡è®°æ•°æ®é›†çš„æƒ…å†µä¸‹æé«˜ FFR å‡†ç¡®æ€§çš„æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡é¢„æµ‹é©±åŠ¨çš„æŽ¨ç† [2]ï¼‰ï¼Œä¸ºæœªæ¥çš„å·¥ä½œæå‡ºäº†ä¸€ä¸ªæœ‰è¶£çš„é¢†åŸŸ

Supporting More Complex LLM Pipelines: æˆ‘ä»¬çš„ç ”ç©¶é‡ç‚¹æ˜¯å•æç¤º LLM pipelineï¼Œä½†æ›´å¤æ‚çš„ç®¡é“ï¼ˆä¾‹å¦‚æ¶‰åŠå¤šä¸ªæç¤ºã€å¤–éƒ¨èµ„æºå’Œäººå·¥äº¤äº’çš„ç®¡é“ï¼‰ä¸ºæ¯ä¸ªç®¡é“ç»„ä»¶è‡ªåŠ¨ç”Ÿæˆæ–­è¨€æä¾›äº†æœºä¼šã€‚ ä¾‹å¦‚ï¼Œåœ¨æ£€ç´¢å¢žå¼ºç”Ÿæˆç®¡é“ä¸­[28]ï¼Œç”šè‡³å¯ä»¥åœ¨ç”Ÿæˆ LLM å“åº”ä¹‹å‰å°†æ–­è¨€åº”ç”¨äºŽæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ã€‚

## RELATED WORK

Prompt Engineering: å¯¹äºŽéžæŠ€æœ¯ç”¨æˆ· [57] å’ŒæŠ€æœ¯ç”¨æˆ· [34, 47] æ¥è¯´ï¼ŒPrompt å·¥ç¨‹å¾ˆå›°éš¾ï¼ŒåŽŸå› æœ‰å‡ ä¸ªï¼šæç¤ºæŽªè¾ž [4, 29] æˆ–æŒ‡ä»¤æˆ–ä¸Šä¸‹æ–‡çš„é¡ºåº [30] çš„å¾®å°å˜åŒ–å¯èƒ½ä¼šæ˜¾ç€å½±å“è¾“å‡ºã€‚ æ­¤å¤–ï¼Œéšç€ LLM åœ¨ API ä¸‹å‘ç”Ÿå˜åŒ–ï¼ˆå³æç¤ºæ¼‚ç§»ï¼‰ï¼Œè¾“å‡ºå¯èƒ½ä¼šåœ¨å¼€å‘äººå‘˜ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹å‘ç”Ÿå˜åŒ– [9]ã€‚ å¸®åŠ©æç¤ºç®¡ç†å’Œå®žéªŒçš„å·¥å…·å’Œè®ºæ–‡ä¸æ–­å‡ºçŽ°ï¼Œç”šè‡³ä½¿ç”¨ LLM æ¥ç¼–å†™æç¤º [3,11,54,55,59]ã€‚ æ­¤å¤–ï¼Œéƒ¨ç½²çš„æç¤ºå¼•å…¥äº†æ–°çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚â€œç”¨æ›´å°‘çš„æ ‡è®°å¹³è¡¡æ›´å¤šçš„ä¸Šä¸‹æ–‡â€å’Œâ€œäº‰è®ºæç¤ºè¾“å‡ºâ€ä»¥æ»¡è¶³ç”¨æˆ·å®šä¹‰çš„æ ‡å‡†[35]ã€‚ æˆ‘ä»¬çš„å·¥ä½œå¹¶ä¸æ˜Žç¡®åœ°ä¸“æ³¨äºŽå¸®åŠ©å¼€å‘äººå‘˜åˆ›å»ºæ›´å¥½çš„æç¤ºï¼Œä½†å®ƒå¯ä»¥é€šè¿‡æŽ¨èçš„æ–­è¨€é—´æŽ¥æ”¯æŒå¼€å‘äººå‘˜æ”¹è¿›æç¤ºã€‚

ML and LLM Evaluation: ä¼—æ‰€å‘¨çŸ¥ï¼Œè¯„ä¼°å’Œç›‘æŽ§å·²éƒ¨ç½²çš„æœºå™¨å­¦ä¹ æ¨¡åž‹å…·æœ‰æŒ‘æˆ˜æ€§ [33, 45]ã€‚ åœ¨éƒ¨ç½²çŽ¯å¢ƒä¸­è¯„ä¼° LLM æ›´å…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸º LLM é€šå¸¸ç”¨äºŽç”Ÿæˆä»»åŠ¡ï¼Œå…¶è¾“å‡ºæ˜¯è‡ªç”±å½¢å¼çš„[13]ã€‚ ä¸€äº› LLM ç®¡é“ç±»åž‹ï¼Œä¾‹å¦‚ä½¿ç”¨æ£€ç´¢å¢žå¼ºç”Ÿæˆç®¡é“çš„é—®ç­” [28]ï¼Œå¯ä»¥ä½¿ç”¨æ ‡å‡†åŒ–çš„è‡ªåŠ¨åŒ–æŒ‡æ ‡ [14, 39]ï¼Œä½†å…¶ä»–ç±»åž‹åˆ™å› æœªçŸ¥æŒ‡æ ‡å’Œç¼ºä¹æ ‡è®°æ•°æ®é›†è€Œé¢ä¸´æŒ‘æˆ˜ [8, 35, 56]ã€‚ é€šå¸¸ï¼Œç»„ç»‡ä¾é äººç±»è¯„ä¼°è€…æ¥è¯„ä¼° LLM çš„è¾“å‡º[19,35,52]ï¼Œä½†æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜Ž LLM å¯ä»¥é€šè¿‡è¯¦ç»†çš„â€œè®°åˆ†å¡â€è¿›è¡Œæœ‰æ•ˆçš„è‡ªæˆ‘è¯„ä¼°[7,26,58]ã€‚ ç„¶è€Œï¼Œç¼–å†™è¿™äº›è®°åˆ†å¡å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ [35]ï¼Œä»Žè€Œæ¿€åŠ±è‡ªåŠ¨ç”Ÿæˆçš„è¯„ä¼°è€…

LLMs for Software Testing: LLM è¶Šæ¥è¶Šå¤šåœ°ç”¨äºŽè½¯ä»¶æµ‹è¯•ï¼Œä¸»è¦ç”¨äºŽç”Ÿæˆå•å…ƒæµ‹è¯•å’Œæµ‹è¯•ç”¨ä¾‹[27,40,48,50,51]ã€‚ ç ”ç©¶æŽ¢è®¨äº† LLM çš„æ¿€åŠ±ç­–ç•¥ã€å¹»è§‰å’Œä¸ç¡®å®šæ€§å¦‚ä½•å½±å“ä»£ç æˆ–æµ‹è¯•çš„å‡†ç¡®æ€§ [10,15,16,32]ã€‚ æˆ‘ä»¬çš„å·¥ä½œæ˜¯äº’è¡¥çš„ï¼Œå¹¶åˆ©ç”¨ LLM ä¸º LLM ç®¡é“ç”ŸæˆåŸºäºŽä»£ç çš„æ–­è¨€

Testing in ML Pipelines: **ML pipelines åœ¨ç”Ÿäº§ä¸­å¾ˆéš¾ç®¡ç†**ã€‚ è®¸å¤šæœ‰å…³æœºå™¨å­¦ä¹ æµ‹è¯•çš„æ–‡çŒ®éƒ½æ˜¯é€šè¿‡åˆ†æžæ•°æ®è´¨é‡ [5, 22, 42, 43] æˆ–æ¥æº [31, 41] æ¥éªŒè¯ç»“æž„åŒ–æ•°æ®ã€‚ ML æµ‹è¯•å¹³å°é€šå¸¸æä¾›è‡ªåŠ¨å®žéªŒè·Ÿè¸ªå’Œé˜²æ­¢è¿‡åº¦æ‹Ÿåˆ [1, 38]ï¼Œä»¥åŠæ•°æ®åˆ†å¸ƒè°ƒè¯•å·¥å…· [20]ã€‚ ç‰¹å®šäºŽæ¨¡åž‹çš„æ–­è¨€é€šå¸¸éœ€è¦äººç±»è§„èŒƒ[25]ï¼Œæˆ–è€…è‡³å°‘éœ€è¦å¤§é‡æ•°æ®æ¥è®­ç»ƒå­¦ä¹ æ–­è¨€[24]ã€‚ **LLM é“¾æˆ–ç®¡é“æ˜¯ä¸€ç±»æ–°åž‹ ML ç®¡é“**ï¼ŒLLM æœ¬èº«å¯ä»¥ç”¨å¾ˆå°‘çš„æ•°æ®ç”Ÿæˆæ–­è¨€ã€‚ æœ€è¿‘çš„ä¸€é¡¹ç ”ç©¶å¼ºè°ƒäº†æµ‹è¯•â€œcopilotâ€ç±»äº§å“çš„ LLM ç®¡é“çš„éš¾åº¦ï¼šå¼€å‘äººå‘˜å¸Œæœ›ç¡®ä¿å‡†ç¡®æ€§ï¼ŒåŒæ—¶é¿å…è¿‡åº¦ä½¿ç”¨èµ„æºï¼Œä¾‹å¦‚è¿è¡Œæ•°ç™¾ä¸ªæ–­è¨€ [35]â€”â€”è¿™æ¿€å‘äº†æˆ‘ä»¬çš„æ–­è¨€è¿‡æ»¤æ–¹æ³•ã€‚

## CONCLUSION

æˆ‘ä»¬çš„å·¥ä½œå¼•å…¥äº†è‡ªåŠ¨ç”Ÿæˆæ–­è¨€ä»¥æ•èŽ· **LLM ç®¡é“ä¸­çš„æ•…éšœçš„æ–°é—®é¢˜**ï¼Œä»¥åŠåŒ…å«ä¸¤ä¸ªç»„ä»¶çš„è§£å†³æ–¹æ¡ˆï¼šé¦–å…ˆï¼Œå®ƒ synthesizes candidate assertionsï¼› ç„¶åŽï¼Œå®ƒä¼š filter å®ƒä»¬ã€‚ æˆ‘ä»¬æå‡ºäº†æ–­è¨€åˆæˆçš„å¿«é€Ÿç¼–è¾‘åˆ†ç±»æ³•ï¼Œé€šè¿‡ä¸Ž LangChain çš„é›†æˆå’Œéƒ¨ç½²å±•ç¤ºäº†å…¶æ½œåŠ›ã€‚ æˆ‘ä»¬å°†ç”¨äºŽé«˜ç²¾åº¦è¦†ç›–æ•…éšœçš„æœ€ä½³æ–­è¨€é›†çš„é€‰æ‹©è¡¨ç¤ºä¸ºæ•´æ•°çº¿æ€§ç¨‹åºï¼ˆILPï¼‰ã€‚ æˆ‘ä»¬æå‡ºäº†æ–­è¨€åŒ…å«æ¥æ¶µç›–æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸­çš„æ•…éšœï¼Œå¹¶å°†å…¶çº³å…¥æˆ‘ä»¬çš„ ILP ä¸­ã€‚ æˆ‘ä»¬çš„è‡ªåŠ¨ç”Ÿæˆæ–­è¨€ç³»ç»Ÿ Spade åœ¨ 9 ä¸ªçœŸå®žæ•°æ®ç”Ÿæˆ LLM ç®¡é“ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ æˆ‘ä»¬å·²å…¬å¼€æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†ä»¥ä¾›è¿›ä¸€æ­¥ç ”ç©¶å’Œåˆ†æž

> æ²¡æœ‰ç†è§£ SPADE base, cov, sub ä¹‹é—´çš„åŒºåˆ«ï¼Œåªæ˜¯é€‰æ‹©çš„é›†åˆä¸åŒå—

> The paper presents SPADE, which is a method to detect incorrect outputs from large language models (LLMs) by automatically synthesizing assertions when developing LLM pipelines (such as codereviews and lecturesummaries). SPADE analyses the prompt version histories and creating candidate assertion functions based on the prompt deltas. Then, SPADE selects a minimal set of assertions or a subset that satisfies the coverage and accuracy requirements, meaning that they can catch most of the errors without causing too many false failures. The paper also uses a pruning technique to remove redundant or contradictory assertions from the final set. Finally, The paper evaluates SPADE on 9 real-world LLM pipelines and shows that it can reduce the number of assertions by 14% and decrease false failures by 21% compared to simpler baselines.

> 1. The paper proposes a novel formulation of synthesizing assertions for LLM pipelines, which takes into account the prompt version histories, the coverage and accuracy requirements, and the trade-off between assertion complexity and number. It also provides an open-source implementation of SPADE and deploy it on the Langchain.
> 2. The SPADE can effectively reduce the number of assertions and false failures compared to simpler baselines, and that spade-generated assertions can help developers improve their LLM pipelines. Spade reduces the number of assertions by 14% and the number of false failures by 21% compared to simpler baselines.
> 3. It evaluates SPADE on nine real-world LLM pipelines, and demonstrates its effectiveness in reducing the number of assertions, increasing the coverage and accuracy of assertions, and identifying bad LLM outputs.

> 1. Like all the applications built on LLM, it relies on the quality of the language model, the ability of LLM correct classificationand the availability of prompt version histories. If the prompt is too large or the language model performs bad, the assertions (python code or string match) might not work.
> 2. The paper does not compare SPADE with Reinforcement Learning from Human Feedback(ChatGPT is enhanced with RLHF to filter inaccurate text and harmful output). SPADE also ignored the very important metrics, recall rate, in the experiment.
> 3. SPADE does not discuss the different effects brought by different assertion implementation methods. For example, most assertions are string matching and many of them might even not work, which may cause some assertions to fail and increase FFR.

> I would try to first compare SPADE with other existing methods for LLM quality control, such as RLHF. Then explore more appropriate assertion implementation methods instead of simple string matching, and discuss the impact of different assertions on FFR. And during the experiment, try to deeply explore the impact of different coverage rates on recall and precision. Finally, try to generalize SPADE to more language models, such as smaller models with less parameters, making the LLM pipeline construction cheaper

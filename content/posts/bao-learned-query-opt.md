+++
title = 'Paper Reading: Bao: Making Learned Query Optimization Practical [SIGMOD 21]'
date = 2024-03-17T00:14:24-04:00
draft = false
tags = ['Paper Reading']
+++

## Bao: Making Learned Query Optimization Practical

MLDB + query optimization

## ABSTRACT

æœ€è¿‘ ML åš query optimization ç”±äºŽéœ€è¦ substantive training overhead æ‰€ä»¥å…¶å®žå¾ˆå°‘ practical gains, inability to adapt to changes, poor tail performance.

è®ºæ–‡æå‡ºäº† Bao, Bandit Optimizer, é€šè¿‡åˆ©ç”¨çŽ°æœ‰æŸ¥è¯¢ä¼˜åŒ–å™¨çš„çŸ¥è¯†ï¼Œå¯¹æ¯ä¸ªæŸ¥è¯¢æä¾›ä¼˜åŒ–å»ºè®®ã€‚

Bao combines mordern tree Convolutional Neural Networks (CNN) with Thompson sampling (RL). Bao å¯ä»¥ä»Žé”™è¯¯ä¸­å­¦ä¹ ï¼Œé€‚åº”ä¸åŒçš„ query workloads, data, schema.

å®žéªŒç»“æžœæ˜¾ç¤º BAO å¯ä»¥å¿«é€Ÿå­¦ä¹ æ”¹å–„**ç«¯åˆ°ç«¯**æŸ¥è¯¢æ‰§è¡Œæ€§èƒ½ï¼ˆåŒ…æ‹¬ tail latencyï¼‰çš„ç­–ç•¥ï¼Œç”¨äºŽå‡ ç§åŒ…å« long-term æŸ¥è¯¢çš„å·¥ä½œè´Ÿè½½ã€‚åœ¨**äº‘çŽ¯å¢ƒ**ä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜Žï¼Œä¸Žå•†ä¸šç³»ç»Ÿç›¸æ¯”ï¼ŒBAO å¯ä»¥æä¾›é™ä½Žçš„æˆæœ¬å’Œæ›´å¥½çš„æ€§èƒ½ã€‚

> é•¿å°¾è¯·æ±‚ï¼šP99, 99% è¯·æ±‚åœ¨ä¸€å®šè€—æ—¶å†…ï¼Œé•¿å°¾è¯·æ±‚å°±æ˜¯æ˜Žæ˜¾é«˜äºŽå‡å€¼çš„é‚£éƒ¨åˆ†æ¯”è¾ƒå°çš„è¯·æ±‚

## INTRODUCTION

Query Optimization, cardinality estimation and cost modeling, difficult to crack

å¾ˆå¤š Query Optimization éƒ½æ˜¯ ML åšçš„ï¼Œä½†å´æ˜¯å¾ˆå°‘å®žç”¨ï¼š

1. Long training time, impractical amount of training data, ML-powered cardinality estimators based on supervised learning éœ€è¦æ”¶é›†ç²¾ç¡®çš„ cardinalitiesï¼Œéžå¸¸æ˜‚è´µçš„æ“ä½œã€‚æ‰€ä»¥ Bao wish to estimate cardinalities in the first place. RL ä¹Ÿéœ€è¦å¥½å‡ å¤©çš„è®­ç»ƒã€‚
2. Inability to adjust to data and workload changes. query workload, data, schema æ˜¯ä¼šå˜çš„ï¼Œcardinality estimators based on supervised learning å°±éœ€è¦é‡æ–°è®­ç»ƒï¼Œä¸ç„¶å°±è¿‡æ—¶äº†ã€‚
3. Tail catastrophe. learning techniques æ¯” traditional optimizers å¹³å‡è¡¨çŽ°æ›´å¥½ï¼Œä½†æ˜¯é•¿å°¾è¡¨çŽ°å¾ˆå·® ï¼ˆ100x regression in query performanceï¼‰ã€‚å°¤å…¶æ˜¯è®­ç»ƒæ•°æ®ä¸è¶³æ—¶ï¼ŒåŒæ—¶ç»Ÿè®¡å’ŒçŽ°å®žè¿˜æ˜¯å…·æœ‰å·®è·.
4. Black-box decisions. DL æ–¹æ³•æ˜¯é»‘ç›’? ä¸Žä¼ ç»Ÿä¼˜åŒ–å™¨ä¸åŒ, å½“å‰å­¦åˆ°çš„ä¼˜åŒ–æ–¹æ³•ä¸èƒ½ç»™ DBA æä¾›æ–¹æ³•
5. Integration cost. å¤§éƒ¨åˆ† learned optimizers éƒ½æ˜¯ç ”ç©¶åŽŸåž‹, å¾ˆå°‘ç»“åˆ DBMS.

Bao å…‹æœäº†ä¸Šé¢çš„é—®é¢˜ï¼Œå¯ä»¥é›†æˆåˆ° PostgreSQLï¼Œhttps://github.com/learnedsystems/baoforpostgresql

æ ¸å¿ƒæ€æƒ³ï¼šé¿å… learning an optimizer from scratchã€‚ take an existing optimizer (PostgreSQLâ€™s
optimizer), and learn when to activate (or deactivate) some of its features on a query-by-query basis. In other words, Bao is a learned component that **sits on top of an existing query optimizer** in order to enhance query optimization, rather than replacing or discarding the traditional query optimizer altogether

> åœ¨ PostgreSQL ä¼˜åŒ–å™¨ä¹‹ä¸Šå¼€å§‹åšä¼˜åŒ–ï¼Œé‚£å¦‚æžœä¹‹å‰çš„ä¼˜åŒ–å™¨ä¸å†æ›´æ–°ï¼Œåˆæˆ–è€…æ›´å¥½çš„ä¼˜åŒ–å™¨å‡ºçŽ°äº†æ€Žä¹ˆåŠžå‘¢ï¼Ÿ

PostgreSQL optimizer might **underestimate the cardinality** for some joins and wrongly select a loop join when other join algorithms (e.g., merge join, hash join) would be more effective
This occurs in query 16b of the **Join Order Benchmark** (JOB)ï¼Œ and disabling loop-joins for this query yields a 3ð‘¥ performance improvement (see Figure 1). Yet, it would be wrong to always disable loop joins. For example, for query 24b, disabling loop joins causes the performance to degrade by almost 50ð‘¥, an arguably catastrophic regression.

![](https://s2.loli.net/2024/03/17/LGqXZjPCFvBbWOp.png)

Bao assumes a **finite set of hint sets** and treats each hint set as an arm in a contextual multi-armed bandit problem.

> multi-armed bandit problem å¤šè‡‚èµŒåšæœºé—®é¢˜ï¼Œæœºå™¨å­¦ä¹ é—®é¢˜ï¼Œæ¯ä¸ªè€è™Žæœºèµ¢çš„æ¦‚çŽ‡ä¸ä¸€æ ·ï¼Œä¸çŸ¥é“æ¦‚çŽ‡ï¼Œé€‰æ‹©å“ªä¸ªèƒ½åšåˆ°æœ€å¤§æ”¶ç›Šï¼Ÿ

Bao learns a model that predicts **which hints will lead to good performance** for a **particular query**. When a query arrives, our system **selects a hint set**, executes the resulting query plan, and observes a reward. Over time, Bao refines its model to **more accurately** predict which hint set will most benefit an incoming query. For example, for a highly selective query, Bao can automatically steer an optimizer towards a left-deep loop join plan (by restricting the optimizer from using hash or merge joins), and to disable loop joins for less selective queries

By formulating the problem as a **contextual multi-armed bandit**, Bao can take advantage of Thompson sampling, a **well-studied sample efficient algorithm**

Because Bao uses an underlying query optimizer, Bao has **cardinality estimates** available, allowing Bao to **adapt to new data and schema changes** just as well as the underlying optimizer. å…¶ä»– learned query optimization éœ€è¦é‡æ–°å­¦ä¹  ä¼ ç»Ÿä¼˜åŒ–å™¨ å·²çŸ¥çš„ä¿¡æ¯ï¼ŒBao å¯ä»¥ç›´æŽ¥å¼€å§‹å­¦ä¹ æ€Žä¹ˆåŽ»è°ƒä¼˜åº•å±‚ä¼˜åŒ–å™¨ï¼Œå¹¶ä¸”ç›¸è¾ƒäºŽä¼ ç»Ÿä¼˜åŒ–å™¨å¯ä»¥å‡å°‘ tail latencyã€‚

1. Short training time, 1 hour, by taking full advantage of existing query optimization knowledge, which was encoded by human experts into traditional optimizers available in DBMSes today
2. Robustness to schema, data, and workload changes, maintain performance even in the presence of workload, data, and schema changes, leveraging a **traditional query optimizerâ€™s cost** and **cardinality estimates**
3. Better tail latency, Bao is capable of **improving tail performance** by orders of magnitude with as little as 30 minutes to a few hours of training
4. Interpretability and easier debugging, be inspected using standard tools,
5. Low integration cost, every SQL
6. Extensibility, adding new query hints over time, w/o retraining. Additionally, Baoâ€™s feature representation can be **easily augmented** with **additional information** which can be taken into account during optimization, although this does require **retraining**. cache state

drawback:

query optimization time increases, Bao must run the traditional query optimizer several times for each incoming query.
for very short running queries,

- Bao is ideally suited to workloads that are **tail-dominated** (80% of query processing time is spent processing 20% of the queries) or contain many long-running queries,
- limited set of hints, Bao has a **restricted action space**, Bao is not always able to learn the best possible query plan.
- outperform **traditional optimizers** while training and adjusting to change orders-of-magnitudes faster than â€œunrestrictedâ€ learned query optimizers, like Neo

> Neo ä¹Ÿæ˜¯å¼ºåŒ–å­¦ä¹  + DNNï¼Œä¹Ÿæ˜¯ç”¨ PG ä¼˜åŒ–å™¨é€šè¿‡è®­ç»ƒç„¶åŽåšä¸€äº›è´ªå¿ƒæœç´¢å¾—åˆ°ä¸€äº›è®¡åˆ’ã€‚å¯èƒ½æ˜¯ query-level çš„ç¼–ç æˆ–è€… plan-level çš„ç¼–ç ä¸åŒï¼Œæ¯”å¦‚è°“è¯çš„è¡¨ç¤ºå€Ÿé‰´äº† word2vec æ•æ‰ rows ä¹‹é—´ç›¸å…³æ€§ï¼Œä¹Ÿç”¨äº† tree DNN æ¥è®­ç»ƒï¼Œvalue model äººä¸ºè®¾è®¡ cost é¢„æµ‹ latencyï¼Œä½†éœ€è¦ä¸æ–­è¿­ä»£ï¼Œå¯¹ ad-hoc æ²¡æœ‰å¤ªå¤§å¸®åŠ©ã€‚

summary:

1. We introduce Bao, a **learned system** for **query optimization** that is capable of **learning how to apply query hints on a case-by-case basis**
2. For the first time, we demonstrate a learned query optimization system that outperforms both open source and commercial systems in **cost and latency**, all while **adapting to changes in workload, data, and schema**.

## SYSTEM MODEL

Bao combines a **tree convolution model**, a **neural network operator** that can recognize important patterns in query plan trees, with Thompson sampling (solving contextual multi-armed bandit problems)

1. **Generating ð‘› query plans**: When a user submits a query, Bao uses the underlying query optimizer to produce ð‘› query plans, one for each set of hint. While some hints can be applied to a single relation or predicate, Bao focuses **only on query hints that are a boolean flag** (e.g., disable loop join, force index usage). The sets of hints available to Bao **must be specified upfront**, empty -> original optimizer
2. **Estimating the run-time** for each query plan: Afterwards, each query plan is transformed into a **vector tree** (a tree where each node is a feature vector) -> value model(tree convolutional neural network) -> which **predicts** the quality (e.g., execution time) of each plan -> parallel
3. Selecting a query plan for execution: best expected performance -> standard supervised fashion and pick the query plan with the best predicted performance. However, **value model** might be wrong, **might not always pick the optimal plan** and never try **alternative strategies** never learn when we are wrong. Thompson sampling explore a specific query offline and guarantee that only the best plan is selected. Once the query execution is complete, the **combination of the selected query plan** and the **observed performance** is added to Baoâ€™s experience. Periodically, this experience is used to retrain the predictive model, creating a feedback loop
4. Assumptions and Limitations: assumes **hints** result in semantically equivalent **query plans**, Bao always uses the hints for the **entire query plan**. Bao cannot restrict features for **only a part of a query plan**. RL converge -> small size of action

> Bao çš„ vaule model æ°¸è¿œä¸ä¼šä»Žé”™è¯¯ä¸­å­¦ä¹ ï¼Ÿè€Œä¸”çœ‹ä¸ŠåŽ»ä¸æ”¯æŒ subquery ä¼˜åŒ–ï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯æ—¶é—´å¤æ‚åº¦å¤ªé«˜çš„åŽŸå› ã€‚

## SELECTING QUERY HINTS

Baoâ€™s learning approach, optimization goal, formalize it as a contextual **multi-armed bandit problem.**, apply Thompson sampling, a classical technique used to solve such problems

Bao models each hint set in the family of hint sets

Bao also assumes a user-defined performance metric ð‘ƒ

Contextual multi-armed bandits (CMABs):

Thompson sampling:

> RL çš„ä¸€äº›ä¸œè¥¿ï¼Œä¸çœ‹äº†

### Predictive model

The core of Thompson sampling, Baoâ€™s algorithm for selecting hint sets on a per-query basis, is a predictive model that estimates the performance of a particular query plan.

> Bao æ˜¯æ€Žä¹ˆè½¬æ¢ query plan trees: **binarizing** the query plan tree and encoding each query plan operator as a vector, optionally augmenting this representation with cache information

**Binarization**: Many queries involve non-binary operations like aggregation or sorting. However, **strictly binary query plan trees** (i.e., all nodes have either zero or two children) are convenient because they greatly **simplify tree convolution** (explained in the next section).

**Vectorization**: Each node in a query plan tree is transformed into a vector containing: (1) a one-hot encoding of the operator, (2) cardinality and cost information, and optionally (3) cache information

> Tree convolutional neural networks

**Integrating with Thompson sampling**: ?

### Training loop

> æå‡ºäº†æ–°çš„ optimization, åœ¨äº‘å¹³å°ä¸Šå¯ä»¥çƒ­åŠ è½½ GPUï¼Ÿ

## POSTGRESQL INTEGRATION

install and use with PostgreSQL, hook system

**Per-query activation**: sits on top of a traditional optimizer, When Bao is activated, Thompson sampling is used to select query hints. When Bao is deactivated, the PostgreSQL optimizer is used. Note that even when Bao is disabled, Bao can (optionally) still learn from query executions. _off-policy reinforcement learning_ ??
**Active vs. advisor mode**: In active mode, Bao operates as described above, **automatically selecting hint sets and learning from their performance**. In advisor mode, Bao does not select hint sets (all queries are optimized by the PostgreSQL planner), but still observes the performance of executed queries and trains a predictive model.
**Triggered exploration**: query regressions, because Bao actively explores new query plans, regressions may be more **erratic**

## RELATED WORKS

One of the earliest applications of learning to query optimization was Leo [72], which used successive runs of the similar queries to adjust histogram estimators.

Neo [51] showed that **deep reinforcement learning** could be applied **directly to query latency**, and could learn optimization strategies that were competitive with commercial systems after 24 hours of training. However, none of these techniques are **capable of handling changes in schema, data, or queryworkload**, and none **demonstrate** improvement in **tail performance**. Works applying reinforcement learning to adaptive query processing have shown interesting results, but are not applicableto existing, non-adaptive systems like **PostgreSQL**.

> æˆ‘ä¸è®¤ä¸º Bao å’Œ Neo æœ‰å¤ªå¤§çš„å·®åˆ«ï¼ŒåŒæ ·éƒ½æ˜¯ RLï¼Œä¸ºä»€ä¹ˆè¯´ Neo æ— æ³•é€‚åº”å˜åŒ–å‘¢ï¼Ÿ

## EXPERIMENTS

real-world database **workloads**, quantifying not only query performance, but also on the **dollar-cost** of executing a workload

### Setup

IMDb dataset, new real-world datasets and workload called Stack, Corp dataset

> å®žéªŒç»“æžœåªæ˜¯å’Œ PG, ComSys æ¯”äº†ä¸€ä¸‹ latencyï¼Œæ•ˆæžœè¿˜ä¸é”™ï¼Œå¤§æ¦‚ 20% çš„æ”¹å–„ï¼Œ P99 ä¹Ÿæ”¹å–„å¾ˆå¤šï¼Œä½†ä¸ºä»€ä¹ˆè¿™éƒ¨åˆ†ä¸å’Œ Neo å¯¹æ¯”å‘¢ï¼Ÿ

**Query optimization time**: The maximum optimization time required by PostgreSQL was 140ms, for the commercial system 165ms, and for **Bao 230ms**. For some applications, a 70ms increase in optimization time could be acceptable. Moreover, our current prototype is simple (e.g., our inference code is in Python), and thus a lot of optimization potential exists

> 230ms æ¯”èµ· 140ms è™½ç„¶ä¸å¤šï¼Œä½†ä¹Ÿä¸ç®—å°‘å§ï¼Œè€Œä¸”ç”¨äº†å¤§é‡å¹¶è¡Œ

**Prior learned optimizers**: Neo [51] and DQ [40] are two other learning based approach to query optimization. Like Bao, Neo uses **tree convolution**, but unlike Bao, Neo **does not select hint sets for specific queries**, but instead fully builds query execution plans on its own. DQ uses deep Q learning [56] with a hand-crafted featurization and a fully-connected neural network (FCNN). We compare performance for the IMDb workload in Figure 14 (average of 20 repetitions on an N1-16 machine with a cutoff of 72 hours).

For Figure 14a, we uniformly at random select a query to create a stable workload, and for Figure 14b we use our original dynamic workload. **With a stable workload, Neo is able to overtake PostgreSQL after 24 hours**, and **Bao after 65 hours**. This is because Neo has many more degrees of freedom than Bao: Neo can use any logically correct query plan for any query, **whereas Bao is limited to a small number of options**. These degrees of freedom come at a cost, as Neo takes significantly longer to converge. After 200 hours of training, **Neoâ€™s query performance was 15% higher than Baoâ€™s**. DQ, with a similar degrees of freedom as Neo, takes longer to outperform PostgreSQL, possibly due to FCNNs having a poor inductive bias [50] for query optimization [51]. With the **dynamic workload** (Figure 14b), Neo and DQâ€™s convergence is significantly hampered, as both techniques struggle to learn a policy robust to the changing workload. With a dynamic workload, neither DQ nor Neo is able to overtake Bao within 72 hours.

> 65h > 24h ä¸ºä»€ä¹ˆ Bao ä¼šè¢« a small number of options é™åˆ¶å‘¢ï¼Œæ–‡ç« ä¹Ÿæ²¡æœ‰ä»”ç»†è§£é‡Š Bao æ˜¯æ€Žä¹ˆé€‚åº” dynamic workload çš„

![](https://s2.loli.net/2024/03/18/dqC2A8ljWtbuI9L.png)

## CONCLUSION AND FUTURE WORK

> å®žé™…ä¸Š Bao å›¢é˜Ÿå’Œ Neo å›¢é˜Ÿéƒ½æ˜¯ä¸€æ‰¹äººï¼Œåº”è¯¥æ˜¯æ³¨é‡ç‚¹ä¸å¤ªä¸€æ ·ï¼š
>
> Neo æ˜¯ç¬¬ä¸€ä¸ªæå‡ºæ·±åº¦å­¦ä¹  query optimizer çš„ï¼Œç”¨ä¸€ä¸ªæœªè¡¥å…¨çš„ query plan encoding ä¹‹åŽç”¨æ ‘å½¢ç½‘ç»œåšé¢„æµ‹ costï¼Œå¹¶ç”¨æœ€å°å †æœç´¢æœ€ä¼˜ planï¼Œå¿½ç•¥ cardinality ç­‰ç­‰ä¼ ç»Ÿï¼Œä¸ºæ¯ä¸ª predicate ç”¨æµ®ç‚¹æ•°å­˜ feature è®¾è®¡ word vector å­˜è¯­ä¹‰ï¼Œå¯èƒ½å¥½äºŽ histgram é¢„æµ‹ã€‚ä½†ç¼ºç‚¹æ˜¯è®­ç»ƒæ—¶é—´é•¿ï¼Œåªåœ¨å¹³å‡ä¸Šæå‡æ¯”è¾ƒå¥½ï¼Œé«˜è´¨é‡çš„è®¡åˆ’å¾ˆå¯èƒ½åœ¨éšæœºæ ·æœ¬ä¸­ç¼ºå¤±ï¼Œæ ·æœ¬é‡å¿…é¡»å¤§ï¼Œæ¨¡åž‹è®­ç»ƒæˆæœ¬å¤ªé«˜ã€‚

> è€Œ Bao æ”¾å¼ƒåš Optimizerï¼Œä¸ºæˆç†Ÿæ•°æ®åº“æä¾› query hints å¦‚ boolean flag è¡¨ç¤ºæ˜¯å¦ä½¿ç”¨ hash join, merge join, index scan ç­‰ç­‰ï¼Œæžšä¸¾æ‰€æœ‰ hint set (access method + join method) è§†ä½œå¤šè‡‚è€è™Žæœºï¼Œç”¨ Thompson sampling å¹³è¡¡é€‰ä¸€ä¸ªæœ€ä¼˜çš„ã€‚è®ºæ–‡æåˆ°äº† Bao æ”¶æ•›å¿«äºŽ Neoï¼Œå¿«å¾ˆå¤šï¼Œè€Œä¸”å¯ä»¥æ ¹æ® workload è°ƒæ•´ï¼Œåœ¨ JOB æ•°æ®é›†ä¸Šè¡¨çŽ°éžå¸¸å¥½ï¼Œä½†è¿˜æ˜¯å¯èƒ½ä¼šåŽ»æŽ‰ä¸€äº›æœ€ä¼˜çš„ï¼Œé€‰æ‹©æ¬¡ä¼˜çš„ã€‚
>
> åŽ»å¹´ä¹Ÿæœ‰ä¸€ç¯‡ Leroï¼Œé‡‡ç”¨æˆå¯¹æ–¹æ³•è®­ç»ƒåˆ†ç±»å™¨ï¼Œä¹Ÿä¸æ˜¯ä»Žå¤´å¼€å§‹ï¼Œå¾ˆç±»ä¼¼ã€‚å°è¯•è§£å†³ Bao çš„ä¸€äº›é—®é¢˜: 1. åœ¨æ•´ä¸ªè®¡åˆ’æœç´¢è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸å¯¹**æ•´ä¸ªæŸ¥è¯¢**åº”ç”¨æç¤ºé›†ã€‚å¦‚æžœæŸ¥è¯¢çš„ä¸åŒéƒ¨åˆ†ï¼ˆå­æŸ¥è¯¢ï¼‰å…·æœ‰ä¸åŒçš„æœ€ä½³é€‰æ‹©ï¼Œåˆ™åœ¨æŸ¥è¯¢çº§åˆ«è°ƒæ•´æ ‡å¿—å¯èƒ½ä¼šé”™è¿‡å¯»æ‰¾é«˜è´¨é‡è®¡åˆ’çš„æœºä¼š 2. å¯ç”¨çš„æç¤ºé›†æ˜¯**ç‰¹å®šäºŽç³»ç»Ÿ**çš„ã€‚ä¼˜åŒ–å™¨é€šå¸¸åŒ…å«æ•°ç™¾ä¸ªæ ‡å¿—æ¥å®žçŽ°/ç¦ç”¨æŸäº›ä¼˜åŒ–è§„åˆ™ã€‚åœ¨å®žè·µä¸­**æžšä¸¾å„ç§ç»„åˆæ˜¯ä¸å¯è¡Œ**çš„ã€‚æ‰‹åŠ¨é€‰æ‹©æç¤ºé›†çš„æœ‰æ•ˆå­é›†éœ€è¦å¯¹ç³»ç»Ÿè¿›è¡Œæ·±å…¥çš„ç†è§£ï¼Œå¹¶å¯¹å·¥ä½œè´Ÿè½½è¿›è¡Œç»¼åˆåˆ†æžã€‚
>
> Lero ç”šè‡³å®žçŽ°äº†ä¸€ä¸ª Bao+, ç”¨æ›´å¤šè®¡åˆ’è¿›è¡Œæ¨¡åž‹è®­ç»ƒï¼Œä½†å¥½åƒæ²¡æœ‰ä»”ç»†è¯´ã€‚åŒæ—¶æ‹“å±•äº†æ›´å¤šçš„æ•°æ®é›†ï¼Œ IMDBï¼ŒJOBï¼ŒSTATSï¼ŒTPC-Hï¼ŒTPC-DSï¼Œç­‰ç­‰

## Paer Reading

> The paper proposes a more practical model called Bao, which sits on top of an existing query optimizer (PostgreSQL) and utilizes machine learning and reinforcement learning for database query optimization. Bao solves lots of the issues with previous learned optimizers, including long training times, inability to adapt, and being difficult to interpret while offers advantages like faster training, robustness to workload and data changes, and better interpretability. The core idea of Bao is to utilize tree convolutional neural networks to analyze query plans and leverage ML techniques called Multi-armed bandit and Thompson Sampling to choose the best query plan among alternatives.

> 1. Bao addresses a major limitation of previous learned optimizers â€“ long training times. By employing Thompson Sampling to solve bandit problem, Bao significantly reduces training time compared to traditional machine learning methods used for query optimization, and achieves similar performance to PostgreSQL in 2 hours training.
> 2. Bao is more robust to changes in schema, data distribution, and query workload. By combining modern tree convolutional neural networks and Thompson sampling to provide query hints, Bao offers interpretability unlike other black-box machine learning models and aims to reduce tail latency and minimize the occurrence of slow-running queries.
> 3. The paper also proposes a new method to optimize resource usage in cloud environments, specifically for tasks involving training a neural network with GPU and then using it for query optimization with CPU, which can reduce overall costs.

> 1. Bao uses Thompson Sampling to enumerate all hint sets in the multi-armed bandit problem, but during the searching process, the hint set is applied to the entire query. If different parts of the query (subqueries) have different best choices, it will lead to the final choice is not optimal.
> 2. Enumerating all collections is very time-consuming, the query optimization time of Bao is nearly 90ms higher than PostgreSQL. And for different systems, the size of the hint sets may be different, somtimes it might include hundreds of boolean flags.
> 3. The architectures of Bao and Neo look very similar, though the authors of these papers are from the same group, the paper does not carefully compare Neo and Bao, especially the performance of training time and query latency.

> First, I would explain the difference between Neo and Bao in more depth, for example, why they all use modern tree convolutional neural networks. Besides, I will collect more data sets and testing their performance on more data benchmarks (such as TPC-H, TPC-DS, STATS). If possible, I would try some methods to limit the hint sets to reduce the current query optimization time, such as manual selection or from expert experiences.

+++
title = 'Paper Reading: MB2: Decomposed Behavior Modeling for Self-Driving Database Management Systems'
date = 2024-04-05T09:50:55-04:00
draft = false
tags = ['Paper Reading']
+++

## MB2: Decomposed Behavior Modeling for Self-Driving Database Management Systems

self-driving database management systems

## ABSTRACT

Database management systems (DBMSs) are notoriously difficult to deploy and administer.**self-driving DBMS** is to remove these impediments by **managing itself automatically**

predict the DBMSâ€™s runtime behavior and resource consumption.

ModelBot2 e2e framework for constructing and maintaining prediction models using **machine learning** (ML) in self-driving DBMSs.

1. decomposes a DBMSâ€™s architecture into fine-grained operating units that make it easier to **estimate the systemâ€™s behavior** for configurations
2. ModelBot2 then provides an offline execution environment to exercise the system to produce the training data used to train its models.

We integrated ModelBot2 in an in-memory DBMS and measured its ability to predict its performance for OLTP and OLAP workloads running in dynamic environments. We also compare ModelBot2 against state-of-the-art ML models and show that our models are up to 25Ã—more accurate in multiple scenarios

> å®Œå…¨è‡ªæ²»çš„æ•°æ®åº“ï¼Œç”¨ ML é¢„æµ‹å’Œä¿®æ”¹é…ç½®ã€‚å’ŒåŒæ ·æ˜¯ Andy ç»„çš„ Ottertune åŒºåˆ«åœ¨å“ªå‘¢ï¼Ÿ

## INTRODUCTION

A self-driving DBMS can configure, tune, and optimize itself **without human intervention**, even as the applicationâ€™s workload, dataset, and operating environment evolve.

Such automation seeks to remove the complications and costs involved with **DBMS deployments**. The core component that underlies a self-driving DBMSâ€™s decision-making is **behavior models** [51]. These models estimate and explain how the systemâ€™s performance changes due to a **potential action** (e.g., changing knobs, creating an index). This is similar to how self-driving vehicles use physical models to guide their autonomous planning [49].

Techniques for constructing database **behavior models** fall under two categories: (1) **â€œwhite-boxâ€ analytical** methods and (2) **ML methods**. Analytical models use a **human-devised formula** to describe a DBMS componentâ€™s behavior, such as the buffer pool or lock manager [42, 45, 74]. These models are customized per DBMS and version. They are difficult to migrate to a new DBMS and require redesign under system updates or reconfiguration. Recent works on using ML methods to construct models have shown that they are more adaptable and scalable than white-box approaches, but they have several **limitations**. These works mostly target isolated query execution [9, 17, 20, 34, 40]. The models that support concurrent queries focus on real-time settings where the interleaving of queries is known [16, 68, 72], but a self-driving DBMS needs to plan for future workloads without such accurate information [37]. Many ML-based models also rely on dataset or workload-dependent information [16, 40, 58]; thus, a DBMS cannot deploy these models in new environments without expensive retraining.

> white-box analytical æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆæŒ‡çš„æ˜¯ Buffer Pool å’Œ Lock Managerï¼Ÿç™½ç›’æ˜¯å¼€å‘äººå‘˜å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„å†…éƒ¨ç»„ä»¶å’Œæºç ï¼Œæ‰€ä»¥èƒ½å¤ŸçŸ¥é“ buffer pool å’Œ lock manager ä¸­çš„å†…å®¹ï¼Œç”šè‡³é¢„æµ‹å—ï¼Ÿ
>
> ä½¿ç”¨ ML æ–¹æ³•æ¥æž„å»ºæ¨¡åž‹ï¼Œæ›´é€‚åˆæ‰©å±•ï¼Œä½†å­˜åœ¨å±€é™ï¼Œä¹‹å‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨éš”ç¦»çš„æŸ¥è¯¢ï¼Œè€Œæ”¯æŒå¹¶è¡ŒæŸ¥è¯¢çš„æ¨¡åž‹ä¸»è¦é›†ä¸­åœ¨å®žæ—¶è®¾ç½®å¹¶ä¸”äº¤ç»‡æŸ¥è¯¢å·²çŸ¥ã€‚å®Œå…¨è‡ªæ²»çš„ DBMS æ— æ³•çŸ¥é“å‡†ç¡®çš„ä¿¡æ¯ï¼Œè€Œä¸”ä¸€äº› ML é¢„æµ‹æ¨¡åž‹ä¾èµ–äºŽæ•°æ®é›†/workload ä¿¡æ¯ã€‚ç”šè‡³è¿˜éœ€è¦è®­ç»ƒã€‚

æœ¬æ–‡æå‡ºäº† ModelBot2 (MB2), generates **behavior models** that estimate the performance of a self-driving DBMSâ€™s components and their interference during concurrent execution. ä½¿å¾— DBMS planning components å¯ä»¥æŽ¨ç†å¯¹ action çš„å½±å“ï¼ŒæœŸæœ›æ”¶ç›Šã€‚æ¯”å¦‚ï¼ŒMB2 å¯ä»¥å›žç­”åˆ›å»ºç´¢å¼•éœ€è¦å¤šé•¿æ—¶é—´ï¼Œç´¢å¼•åˆ›å»ºä¼šæ€Žä¹ˆå½±å“ç³»ç»Ÿæ€§èƒ½ï¼Œæ–°ç´¢å¼•ä¼šå¦‚ä½•åŠ é€Ÿ workload's queryã€‚

MB2 ä¸»è¦æ€æƒ³æ˜¯åˆ†è§£ DBMS çš„å†…éƒ¨ç»“æž„ï¼Œåˆ†æˆäº†å‡ ä¸ªå°çš„ã€äº’ç›¸ç‹¬ç«‹çš„æ“ä½œå•å…ƒ operating units (OUs) (e.g., building a hash table, flushing log records).

MB2 then uses ML methods to **train an OU-model** for each OU that **predicts its runtime** and **resource consumption** for the **current DBMS state**ã€‚ å°çš„ OU å•å…ƒæ¨¡åž‹éœ€è¦æ›´å°‘çš„è®­ç»ƒæ—¶é—´ï¼Œå¹¶ä¸”å¯¹æ¯ä¸ª DBMS ç»„ä»¶éƒ½æœ‰æ€§èƒ½ insightã€‚æŽ¨ç†æ—¶ï¼ŒMB2 ç»“åˆæ‰€æœ‰ OU-models é¢„æµ‹ DBMS å¯¹æœªæ¥çš„ workload çš„æ€§èƒ½å’Œç³»ç»ŸçŠ¶æ€ï¼ˆå·¥ä½œé‡ä¹Ÿæ˜¯é¢„æµ‹çš„ï¼‰ã€‚

multi-core environments with concurrent threads, MB2 also estimates the interference between OUs by defining the OUmodelsâ€™ outputs as a set of measurable performance metrics that summarizes each OUâ€™s behavior

> æ‹†æˆæ›´å°å•å…ƒï¼Œè®­ç»ƒæ¯ä¸ªå°çš„ï¼Œè”åˆé¢„æµ‹ã€‚è¯„æµ‹ç»“æžœæ”¯æŒ OLTP OLAP å·¥ä½œè´Ÿè½½ï¼Œwith a minimal loss of accuracy

## BACKGROUND AND MOTIVATION

ç±»æ¯” self-driving DBMS å’Œæ— äººé©¾é©¶ï¼ŒåŒæ ·æœ‰ 1. forecasting 2. behavior model 3. planning system

The **forecasting system** is how the DBMS observes and predicts the applicationâ€™s future workload

The DBMS then uses these **forecasts** with its **behavior models** to predict its **runtime behavior** relative to the target **objective function** (e.g., latency, throughput). The DBMSâ€™s planning system selects actions that **improve this objective function**

> é¢„æµ‹ + action + ç›®æ ‡å‡½æ•°
>
> Behavior models æ˜¯åŸºç¡€

### Behavior Modeling

Given an **action**, a self-driving **DBMSâ€™s behavior models estimate** (1) **how long** the action takes, (2) **how much resource** the action consumes, (3) how applying the action **impacts the system performance**, and (4) how the action impacts the system once it is deployed.

> å¯¹æ¯” Analytical models å’Œ Behavir Modelï¼Œå‰è€…æœ€è¿‘å¯ä»¥ç”¨ ML åˆ†æžï¼Œç”¨ query plan information (cardinality estimates) ä¼°è®¡æ€§èƒ½å‚æ•° (latency)

å°½ç®¡ ML æ–¹æ³•å¯æ‰©å±•ï¼Œä½†è¿˜éœ€è¦è°ƒæ•´æˆ–é‡æ–°è®­ç»ƒï¼Œè€Œä¸”ä¸æ”¯æŒäº‹åŠ¡ workloadï¼Œä¹Ÿæ²¡è€ƒè™‘ DBMS ç»´æŠ¤æ“ä½œï¼ˆGCï¼‰ã€‚ä¸€äº›æ–¹æ³•æ”¯æŒå¹¶å‘æŸ¥è¯¢ï¼Œä½†å¯¹å®Œå…¨è‡ªæ²»çš„ DBMS è¿˜ä¸å¤Ÿï¼Œå› ä¸ºæœªæ¥å·¥ä½œé‡æœªçŸ¥ã€‚

ä¸¾äº†ä¸ªä¾‹å­ï¼Œå¦‚æžœåˆ é™¤äºŒçº§ç´¢å¼•ï¼ŒDBMS ä¼šé‡æ–°åŠ å›žæ¥ï¼Œå¯åŠ¨ä¹‹å‰ä¼šç”¨ planning component å’Œ behavior model é¢„æµ‹ä»€ä¹ˆç´¢å¼•æ¯”è¾ƒå¥½ï¼Œè¿˜ä¼šé€‰æ‹©åˆ›å»ºç´¢å¼•çš„çº¿ç¨‹æ•°ã€‚

### Challenges

ML æ–¹æ³•å»ºé€ ä¸€ä¸ªè‡ªæ²» DBMS ä¼šé‡åˆ°çš„é—®é¢˜ï¼š

1. High Dimensionality é«˜çº¬åº¦ï¼Œä¸€ä¸ªå¤§æ¨¡åž‹æ•æ‰ DBMS æ‰€æœ‰æ–¹é¢ï¼Œworkload, configuration, actions. è‡ªæ²» DBMS è¿˜éœ€è¦è€ƒè™‘ runtime state (e.g., database contents, knob configurations), interactions with other components (e.g., garbage collection), and other autonomous actions (e.g., building indexes), which further increases dimensionality
2. Concurrent Operations å¹¶è¡Œæ“ä½œï¼ŒåŠ¨æ€çŽ¯å¢ƒ query ä¹‹é—´çš„å¹²æ¶‰ interferenceï¼Œèµ„æºç«žäº‰ã€‚
3. Training, Generalizability, and Explainabilityï¼Œèµ„æºæ”¶é›†æ¯”è¾ƒå›°éš¾ï¼Œæž„å»ºç´¢å¼•è€—æ—¶å¾ˆä¹…ã€‚

## OVERVIEW

MB2, embedde behavior modeling framework for self-driving DBMS.

1. MB2 generates model offline in a dataset and workload independent manner
2. MB2's models are debuggable, explainable, and adaptable.

![](https://s2.loli.net/2024/04/07/qeu2KP76GgmdZ9w.png)

decompose the DBMS into independent operating units (OUs). An OU represents a step that the DBMS performs to **complete a specific task**. These tasks include query execution steps (e.g., building join hash tables (JHTs)) and internal maintenance steps (e.g., garbage collection). DBMS developers are responsible for creating OUs and deciding their boundaries based on the systemâ€™s implementation.

MB2 **pairs each OU with an OU-runner** that exercises the OUâ€™s corresponding DBMS component by sweeping the componentâ€™s input parameter space. MB2 then provides a lightweight **data collection layer** to transform these OU-runnersâ€™ inputs to OU features and track the OUâ€™s behavior metrics (e.g., runtime, CPU utilization). For each OU, MB2 automatically searches, trains, and validates an OU-model using the data collected from the related OU-runner

simulate concurrent enviornments, MB2 uses concurrent runners to execute e2e workloads.

![](https://s2.loli.net/2024/04/07/EJNafQ5emIut2Lw.png)

> å°†æ•°æ®åº“æ“ä½œæ‹†æˆ OU å’Œå¯¹åº”çš„ OU runnerï¼Œæ¯”å¦‚åˆ›å»ºç´¢å¼•ã€åžƒåœ¾å›žæ”¶ã€Flush Logï¼Œå¼€å‘è€…æ¥æä¾› OU é›†åˆã€‚OU runner ç”¨äºŽè®­ç»ƒ OU æ¨¡åž‹ï¼Œéœ€è¦çŸ¥é“æœ‰å¤šå°‘ tuple, column ç­‰ç­‰ï¼Œä»¥åŠ output feature: CPU, memory utilization, IO ç­‰ç­‰ã€‚

MB2 also **estimates** the effect of building the index on the regular workload by converting its queries into OUs and predicting their performance. The DBMSâ€™s **planning system** then decides whether to build this index and provides explanations for its decision based on these detailed predictions

Assumptions and Limitations:

1. framework uses a **forecasting system** to generate estimations for future workload arrival rates in fixed intervals (e.g., a minute/hour). The workload forecasting system cannot predict **ad-hoc queries** it has never seen before. Thus, we assume the DBMS executes queries with a **cached query plan** except for the initial invocation
2. the target system is an in-memory DBMS. MB2 does not support disk-oriented DBMSs with buffer pools. This assumption **simplifies** MB2â€™s behavior models since it does not have to consider what pages could be in memory for each query. Estimating cache contents is difficult enough for a single query. It is more challenging when evaluating a sequence of forecasted queries.
3. MB2 supports OLTP and OLAP, and mixed workloads. We assume that the DBMS uses **MVCC** and MB2 supports **capturing lock contention**. MB2 does not, however, **model transaction aborts** due to data conflicts because it is challenging to **get precise forecasts of overlapping queries**
4. MB2â€™s OU-modelsâ€™ input features contain the **cardinality estimation** from the **DBMS optimizer**, which is known to be error-prone Our evaluation shows that MB2â€™s prediction is insensitive against cardinality estimation errors within a reasonable range (30%). There are recent works that **use ML to improve an optimizerâ€™s cardinality estimations** , which MB2 may leverage
5. Lastly, while MB2 supports **hardware context** in its models (see Sec. 4.2), we **defer the investigation** on what features to include for different hardware (e.g., CPU, disk) and environments (e.g., bare-metal, container) as future work.

> æ²¡æ³•é¢„æµ‹ ad-hoc ç”¨æˆ·è‡ªå·±çš„æ•°æ®é›†ï¼Œé¢„æµ‹ç¼“å­˜éžå¸¸å›°éš¾ã€‚ä¹Ÿåªæ”¯æŒå†…å­˜æ•°æ®åº“ã€‚

## OU-MODELS

create a **DBMSâ€™s OU-models** with MB2. The goal of these models is to **estimate the time and resources** that the DBMS will consume to execute a query or action. A self-driving DBMS can **make proper planning decisions** by combining these **estimates** from multiple queries **in a workload forecast interval**. In addition to accuracy, these models need to have three properties that are important for self-driving operations: (1) they provide **explanations** of the DBMSâ€™s behavior, (2) they support **any dataset and workload**, and (3) they **adapt to DBMS software updates**

> é™¤äº†ç²¾ç¡®åº¦ï¼Œèƒ½å¤Ÿæä¾›è§£é‡Šã€æ”¯æŒä»»ä½•æ•°æ®é›†ã€æ”¯æŒåŠ¨æ€æ›´æ–°

### Principles

Developers use MB2 to **decompose the DBMS into** OUs to build explainable, adaptable, and workload independent behavior models.

> å¼€å‘äººå‘˜æ¥åš decompose, å› ä¸º NoisePage æ˜¯ CMU è‡ªå·±çš„å…³ç³»åž‹æ•°æ®åº“ï¼Œå¯ä»¥æ‹†é™¤å¾ˆå¤šæ“ä½œå•å…ƒï¼Œæ¯”å¦‚ Hash Table Build, Probe ç­‰ç­‰

![](https://s2.loli.net/2024/04/07/QzVqtXFArI7Y4HS.png)

1. Independent: The runtime behavior of an OU must be **independent of other OUs**. Thus, changes to one OU do not directly affect another unrelated OU. For example, if the DBMS changes the knob that controls the **join hash table size** then this does not change the resource consumption of the DBMSâ€™s **WAL component** or the resource consumption of sequential scans for the same queries.

> æ¯”è¾ƒå¥½å¥‡æ€Žä¹ˆæ‹†æˆç‹¬ç«‹çš„ OUï¼Œå¦‚æžœæ”¹ join hash table sizeï¼Œä¼šä¸ä¼šå½±å“ join table probe OU å‘¢

2. Low-dimensional: An OU is a **basic operation** in the DBMS with a small number of input features.
3. Comprehensive: Lastly, the framework must have OUs that encompass all DBMS operations which consume resources. Thus, **for any workload**, the OUs **cover the entire DBMS**, including background maintenance tasks (e.g., garbage collection) and self-driving actions that the DBMS may deploy on its own (e.g., index creation).

> OU åˆ°åº•æ˜¯å¯¹ DBMS è®¾ç½®ï¼Œè¿˜æ˜¯é’ˆå¯¹æ•°æ®é›†è®¾ç½®çš„ï¼Ÿ

### Input Features

After deciding which OUs to implement, DBMS developers then specify the OU-modelsâ€™ input features based on their **degree of freedom**

1. the **amount of work** for a single OU invocation or multiple OU invocations in a batch (the number of tuples to process)
2. the parallel invocation status of an OU (e.g., number of threads to create an index), and
3. the DBMS **configuration knobs** (e.g., the execution mode).

> degree of freedom ç»Ÿè®¡å­¦æ¦‚å¿µï¼Ÿ

![](https://s2.loli.net/2024/04/07/jgJdQK4GrBAu9Oo.png)

Although **humans select the features for each OU-model**, the featuresâ€™ **values are generated automatically** by the DBMS based on the workload and actions. Some features are generic and will be the same **across many DBMSs**, whereas others are specific to a DBMSâ€™s implementation. We categorize OUs into three types based on their behavior pattern, which impacts what information the input features have

1. Singular OUs: The first type of OUs have input features that represent the amount of work and resource consumption for a **single invocation**. These include NoisePageâ€™s execution category OUs in Table 1. Almost all its execution OUs have the same seven input features. The first six features are related to the relational operator that the OU belongs to: (1) **number of input tuples**, (2) number of columns of input tuples, (3) average input tuple size, (4) estimated key cardinality (e.g., sorting, joins), (5) payload size (e.g., hash table entry size for hash joins), and (6) number of loops (only for index nested loop joins). Lastly, the seventh feature is an **execution mode flag** that is specific to NoisePage; this indicates whether the DBMS executes a query with its **interpreter** or as **JIT-compiled**. NoisePageâ€™s networking OU also belongs to this type since network communication is discrete amount of work.
2. Batch OUs: The second type of OUs have input features that represent a batch of work across multiple OU invocations. It is challenging to derive features for these OUs since a single invocation **may span multiple queries based on when those queries arrive and the invocation interval**. (log flushes) To address this, we define the log flush OUâ€™s input features to represent the total amount of records generated by the set of queries predicted to arrive in a workload forecasting interval: (1) the total number of bytes, (2) the total number of log buffers, and (3) the log flush interval. These features are independent of what plans the DBMS chooses for each query
3. Contending OUs: The last type of OUs are for operations that may **incur contention in parallel invocations**.

> ç‹¬ç«‹çš„ OUï¼Œæ‰¹å¤„ç† OUï¼Œç«žäº‰ OUã€‚ç¬¬ä¸€ä¸ªå¯ä»¥è¿ç§»ï¼Œå› ä¸º input ç±»ä¼¼ï¼Œæ¯”å¦‚è¡Œæ•°ã€åˆ—æ•°ã€è¡Œå¤§å°ã€åŸºæ•°ç­‰ç­‰ã€‚ç¬¬äºŒä¸ªå¯èƒ½è·¨ query æ¯”å¦‚æ—¥å¿—è½ç›˜ã€‚ç¬¬ä¸‰ä¸ªæ˜¯å¹¶è¡Œå¯èƒ½å¼•èµ·é”ç«žäº‰çš„ OUï¼Œæ¯”å¦‚å¤šçº¿ç¨‹æž„å»ºç´¢å¼•ï¼Œéœ€è¦çŸ¥é“è¡Œæ•°ã€key æ•°é‡ã€key å¤§å°ã€key åŸºæ•°ä¼°è®¡ã€ç­‰ç­‰

A self-driving DBMS must also predict **how changes to its configuration knobs impact its OUs**. We categorize these tunable knobs into **behavior knobs** and **resource knobs**.

### Output Labels

Every OU-model produces the same output labels, (1) elapsed time, (2) CPU time, (3) CPU cycles, (4) CPU instructions, (5) CPU cache references, (6) CPU cache misses, (7) disk block reads, (8) disk block writes (for logging), and (9) memory consumption.

These **metrics explain what work an OU does independent of which OU it is**. Using the same labels enables MB2 to combine them together to **predict the interference among concurrent OUs**. They also help the self-driving DBMS estimate the **impact of knobs** for resource allocation. For example, the OU-models can predict each queryâ€™s memory consumption by predicting the memory consumption for all the OUs related to the query. A self-driving DBMS evaluates what queries can execute under the knob that limits the working memory for each query, and then sets that knob according to its memory budget. Similarly, CPU usage predictions help a self-driving DBMS evaluate whether it has assigned enough CPU resources for queries or its internal components

> OU-model è¾“å‡º labelï¼Œæ‰€ä»¥æœ‰åˆ©äºŽ debug

**Output Label Normalization**: We now discuss how MB2 normalizes OU-modelsâ€™ output labels by tuple counts to improve their accuracy and efficiency. DBMSs can execute queries that range from accessing a single tuple (i.e., OLTP workloads) to scanning billions of tuples (i.e., OLAP workloads). The former is fast to replicate with OU-runners, but the latter is expensive and time-consuming. To overcome this issue, MB2 employs a normalization method inspired by a previous approach for **scaling query execution modeling** [34]. We observe that many OUs have a known complexity based on the number of tuples processed, which we denote as ð‘›. For example, if we fix all the input features except for ð‘›, the time and resources required to build a hash table for a join are O(ð‘›). Likewise, the time and resources required to build buffers for sorting are O(ð‘› log ð‘›). We have found in our evaluations with NoisePage that with typically less than a million tuples, the output labels converge to the OUâ€™s asymptotic complexity multiplied by a constant factor

> å¦‚ä½•å¤„ç† labelï¼Ÿä½¿ç”¨ normalize, divides the outputs by the related OUâ€™s complexity **based on the number of tuples**, ä½†æ˜¯æž„å»ºå“ˆå¸Œè¡¨æ—¶ï¼Œç”±äºŽ NoisePage ä½¿ç”¨ä¸åŒçš„å“ˆå¸Œè¡¨å¤„ç† join å’Œ aggï¼šé¢„å…ˆåˆ†é…å†…å­˜ç»™ joinï¼Œå“ˆå¸Œè¡¨ä¼šå¯¹æ’å…¥çš„ unique key é¢å¤–å¢žé•¿ã€‚æ‰€ä»¥ MB2 éœ€è¦ç”¨é™¤æ³•æ¥å½’ä¸€åŒ–ã€‚

## INTERFERENCE MODEL

The OU-models capture the **internal contention on data structures or latches within an OU** (Sec. 4.2). But there can also be interference among OUs due to resource competition, such as CPU, I/O, and memory.2 MB2 builds a common interference model to capture such interference since it may impact any OU.

> è®ºæ–‡ä¹Ÿè§‚å¯Ÿåˆ°ï¼ŒOU ä¹‹é—´ä¹Ÿå­˜åœ¨èµ„æºå…±äº«ï¼Œæ¯”å¦‚è¿žç»­è¿è¡Œçš„ OU ä¼šæœ‰ç¼“å­˜å±€éƒ¨æ€§ã€‚ä½†è®ºæ–‡è¯´è¿™æ˜¯æžç«¯æƒ…å†µã€‚

Building such an interference model has two challenges: (1) there are an **exponential number of concurrent OU combinations**, and (2) self-driving DBMSs need to **plan actions ahead of time** [50], but predicting queriesâ€™ exact future arrival times and concurrent interleavings is arguably impossible

> éœ€è¦æå‰é¢„æµ‹ï¼Œä½†ä¸èƒ½ç²¾ç¡®é¢„æµ‹å¹¶è¡Œå‘ç”Ÿçš„æ—¶é—´ï¼Œå¹¶ä¸” OU ç»„åˆæ˜¯æŒ‡æ•°çº§çš„

### Input Features

The interference modelâ€™s inputs are the OU-modelâ€™s output labels for the OU to predict and summary statistics of the OUs forecasted to run **in the same interval** (e.g., one minute).

### Output Labels

The interference model generates the same set of outputs as the OU-models.

## DATA GENERATION AND TRAINING

MB2 is an **end-to-end solution** that enables self-driving DBMSs to **generate training data from OUs** and then **build accurate models that predict their behavior**.

> MB2 å¦‚ä½•æœ‰åˆ©äºŽæ”¶é›†æ•°æ®å’Œè®­ç»ƒæ¨¡åž‹ï¼Œå¹¶ä¸”å†æ¬¡å¼ºè°ƒéœ€è¦åœ¨ç¦»çº¿æƒ…å†µä¸‹ï¼Œéžç”Ÿäº§çŽ¯å¢ƒï¼Œè¿è¡Œ MB2ã€‚æŽ¨è¿Ÿäº†å¦‚ä½•åœ¨åœ¨çº¿ç³»ç»Ÿæ”¶é›†æ•°æ®ï¼Œè€Œä¸ä¼šå¯¼è‡´æ€§èƒ½è§‚å¯Ÿé€€åŒ–çš„é—®é¢˜ã€‚

### Data Collection Infrastructure

**OU Translator**: This component extracts OUs from query and action plans and then generates their corresponding input features. MB2 uses the same translator infrastructure for both **offline training** data collection and **runtime inference**.

**Resource Tracker**: Next, MB2â€™s tracker records the **elapsed time** and **resource consumption metrics** (i.e., output labels) during OUs execution. The framework also uses this method for the interference model data since it uses the **same output labels** to adjust the OU-modelsâ€™ outputs.

**Metrics Collector**: The challenges with collecting training data are that (1) **multiple threads** produce metrics and thus require coordination, and (2) resource tracker can incur a **noticeable cost**. It is important for MB2 to support low-overhead metrics collection to reduce the cost of accumulating training data and interference with the behavior of OUs, especially in concurrent environments

MB2 uses a **decentralized metrics collector** to address the first issue. When the DBMS executes in **training mode**, a worker thread records the features and metrics for each OU that it encounters in its thread-local memory. MB2 then uses a **dedicated aggregator** to periodically gather this data from the threads and **store it in the DBMSâ€™s training data repository**. To address the second challenge, MB2 supports resource tracking **only for a subset of queries** or DBMS components. For example, when MB2 collects training data for the OUs in the execution engine, the DBMS can turn off the tracker and metrics collector for other components

> æ•°æ®æ”¶é›†çš„æž¶æž„

### OU-Runners

An OU-runner is a **specialized microbenchmark** in MB2 that exercises a single OU. The goal of each OU-runner is to reproduce situations that an OU could encounter when the DBMS executes a real applicationâ€™s workload. The OU-runners sweep the input feature space (i.e., number of rows, columns, and column types) for each OU with fixed-length and exponential step sizes, which is similar to the grid search optimization

There are two ways to implement OU-runners: (1) **low-level execution code** that uses the DBMSâ€™s **internal API** and (2) high level **SQL statements**. We chose the **latter** for NoisePage because it requires less upfront engineering effort to implement them, and has little to no maintenance costs if the DBMSâ€™s internal API changes

> ç”¨ SQL statement å®žçŽ° OU runner æ˜¯æ€Žä¹ˆåšåˆ°çš„

MB2 supports modeling OLTP and OLAP workloads. To the best of our knowledge, we are the first to support both workload and **data-independent** modeling for OLTP query execution. Prior work either focused on modeling OLAP workloads [34, 40, 68] or assumes a fixed set of queries/stored procedures in the workload [42, 45]. Modeling the query execution in OLTP workloads is challenging for in-memory DBMSs: since OLTP queries access a small number of tuples in a short amount of time, spikes in hardware performance (e.g., CPU scaling), background noise (e.g., OS kernel tasks), and the precision of the resource trackers (e.g., hardware counters) can inflict large variance on query performance. Furthermore, DBMSs typically execute repeated OLTP queries as prepared statements

> ç¬¬ä¸€ä¸ªæ”¯æŒ OLAP å’Œ OLTP æ•°æ®é›†ï¼Œå¹¶ä¸”æ˜¯ workload and data-independent çš„ï¼Œæ”¯æŒ OLTPã€‚ä½† NoisePage æœ¬èº«å°±æ˜¯äº‹åŠ¡æ•°æ®åº“ï¼ŒMB2 æ˜¯æ€Žä¹ˆåšåˆ°è¿™ç§ç‰¹æ€§çš„ã€‚

1. MB2 executes the OU-runners for the OUs in the execution engine with **sufficient repetitions** (10Ã—) and applies robust statistics to derive a reliable measurement of the OUâ€™s behavior.
2. MB2 executes each query for **five warm-up iterations** before taking measurements for the queryâ€™s OUs, with all executions of a given query using the same query template. MB2 starts a new transaction for each execution to avoid the data residing in CPU caches. For queries that modify the DBMS state, MB2 reverts the queryâ€™s changes using transaction rollbacks. We find the labels insensitive to the trimmed mean percentage and the number of warm-up iterations.

> å¤šæ¬¡é‡å¤å’Œ warm upï¼Œæ‰€ä»¥è¿™æ˜¯æ²¡æ³•åœ¨ ç£ç›˜ DBMS ä½¿ç”¨ MB2 çš„åŽŸå› å—ï¼Œæ²¡æœ‰åŠžæ³•é¢„æµ‹ buffer pool ä¸­çš„å†…å®¹ï¼Œé‚£ NoisePage æœ‰ç¼“å­˜å—ï¼Ÿ

MB2 starts a new transaction for each execution to avoid the **data residing in CPU caches**. For queries that modify the DBMS state, MB2 reverts the queryâ€™s changes using transaction rollbacks. We find the labels insensitive to the trimmed mean percentage and the number of warm-up iterations.

> æ¯æ¬¡éƒ½æ˜¯ç”¨äº‹åŠ¡ï¼Œé¿å…äº† CPU data cacheï¼Œå¹¶ä¸”ç”¨ rollback æ”¹å›žäº† DBMS çš„çŠ¶æ€ã€‚label å’Œ trimmed mean percentage and warmup iterations ä¸æ•æ„Ÿã€‚é‚£ä¸ºä»€ä¹ˆè¦ warm upï¼Ÿ

### Concurrent Runners

Since OU-runners invoke their SQL queries **one at a time**, MB2 also provides concurrent runners that execute end-to-end benchmarks (e.g., TPC-C, TPC-H). These concurrent runners provide MB2 with the necessary data to train its **interference model**

### Model Training

Lastly, we discuss how MB2 trains its behavior models using the **runner-generated data**. Since OUs have **different input features** and **behaviors**, they may require using **different ML algorithms** that are better at handling their unique properties and assumptions about their behavior. For example, Huber regression (a variant of linear regression) is simple enough to model the filter OUs with arithmetic operations. In contrast, sorting and hash join OUs require more complex models, such as random forests, to support their behaviors under different key number, key size, and cardinality combinations

> ä½¿ç”¨ä¸åŒçš„ ML æ–¹æ³•ï¼Œé‚£æ€Žä¹ˆé€‰ï¼Ÿ

MB2 trains multiple models per OU and then **automatically selects the one with the best accuracy for each OU**. MB2 currently supports seven ML algorithms for its models: (1) linear regression, (2) Huber regression, (3) support vector machine, (4) kernel regression, (5) random forest, (6) gradient boosting machine, and (7) deep neural network. For each OU, MB2 first trains an ML model using each algorithm under the common 80/20% train/test data split and then uses cross-validation to determine the best ML algorithm to use. MB2 then trains a final OU-model with all the available training data using **the best ML algorithm determined previously**. Thus, MB2 utilizes all the data that the runners collect to build the models. MB2 uses this same procedure to train its interference models.

> è‡ªåŠ¨é€‰äº† ML æ–¹æ³•ï¼ˆç²¾åº¦æœ€é«˜çš„ï¼‰

## HANDLING SOFTWARE UPDATES

è®¨è®ºäº† DBMS å¯ä»¥æ›´æ–°ï¼ˆbug ä¿®å¤ï¼Œæ€§èƒ½æå‡ç­‰ç­‰ï¼‰çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨é©¾é©¶çš„ DBMS åº”è¯¥æ€Žä¹ˆå¤„ç†ã€‚å› ä¸º OUs ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼ŒMB2 åªéœ€è¦é‡æ–°è·‘å—å½±å“çš„ OU-runners ã€‚ This restricted retraining is possible because the **OUs are independent of each other**. The OU-runners issue SQL queries to the DBMS to exercise the OUs, which means that developers do not need to update them unless there are changes to the DBMSâ€™s SQL syntax. Furthermore, MB2 does not need to retrain its interference models in most cases because resource competition is not specific to any OU.

In NoisePage, we currently use a heuristic for MB2 to retrain the interference models when a DBMS update affects at least five OUs

> ä¸éœ€è¦é‡æ–°è®­ç»ƒå¹²æ‰°æ¨¡åž‹ï¼Œåªéœ€è¦é‡æ–°è·‘ OU runnerã€‚é™¤éž DBMS å¼•å…¥äº†æ–°çš„ OU behavior æ¯”å¦‚æ–°çš„ç»„ä»¶ï¼ŒMB2 å°±éœ€è¦é‡æ–°è¿è¡Œ OU concurrent runners ç”Ÿæˆå¹²æ‰°æ¨¡åž‹ã€‚

## EXPERIMENTAL EVALUATION

NoisePage DBMS: OLTP-Bench testbed as an end-to-end workload generator for the SmallBank, TATP , TPC-C, and TPC-H benchmarks.

> OLAP å’Œ OLTP éƒ½æµ‹äº†ï¼Œä½¿ç”¨ä¸åŒçš„æŒ‡æ ‡

We use two evaluation metrics. For OLAP workloads, we use the **average relative error** ( |ð´ð‘ð‘¡ð‘¢ð‘Žð‘™âˆ’ð‘ƒð‘Ÿð‘’ð‘‘ð‘–ð‘ð‘¡| ð´ð‘ð‘¡ð‘¢ð‘Žð‘™ ) used in similar prediction tasks in previous work . Since OLTP queries have short run-times with high variance, their relative errors are too noisy to have a meaningful interpretation. Thus, we use the **average absolute error** ( |ð´ð‘ð‘¡ð‘¢ð‘Žð‘™ âˆ’ð‘ƒð‘Ÿð‘’ð‘‘ð‘–ð‘ð‘¡|) per OLTP query template

### Data Collection and Training

MB2â€™s data collection and model training.

![](https://s2.loli.net/2024/04/07/R17TNgndqQ5AGaE.png)

> çœ‹ä¸ŠåŽ»è®­ç»ƒæ•°æ®ä¸æ˜¯å¾ˆå¤§ï¼Œè®­ç»ƒæ—¶é—´ä¹Ÿä¸æ˜¯å¾ˆä¹…ã€‚

### OU-Model Accuracy

the OU-model test relative error averaged across all output labels. More than 80% of the OU-models have an average prediction error less than 20%, which demonstrates the effectiveness of the OU-models.

> OU æ¨¡åž‹çš„é¢„æµ‹è¯¯å·®å°äºŽ 20%ï¼Œè¯æ˜Žäº†æœ‰æ•ˆæ€§ã€‚ä½†æ²¡çœ‹æ‡‚è¿™ä¸ªç»“æžœï¼Œç”¨ä¸åŒçš„ ML æ–¹æ³•å¾—åˆ°çš„è¯¯å·®éƒ½ä¸åŒï¼Œæœ‰çš„å¾ˆä½Žæœ‰çš„å¾ˆé«˜ï¼Œæ¯”å¦‚éšæœºæ£®æž—æ€»æ˜¯å¾ˆä½Žçš„è¯¯å·®ï¼Œè®ºæ–‡ä¹Ÿæåˆ° OU æ¨¡åž‹ç»´åº¦å¾ˆä½Žï¼Œå®¹æ˜“å‡ºçŽ°è¿‡æ‹Ÿåˆã€‚

we show the predictive accuracy of the OU-models for each output label, averaging across all OUs. Most labels have an average error of less than 20%, where the highest error is on the cache miss label. **Accurately estimating the cache misses for OUs is challenging because the metrics depend on the real-time contents of the CPU cache**. Despite the higher cache miss error, MB2â€™s interference model still captures the interference among concurrent OUs (see Sec. 8.4) because the interference model extracts information from all the output labels. The results in Fig. 6 also show the OU-model errors without output label normalization optimization from Sec. 4.3. From this, we see that normalization has minimal impact on OU-model accuracy while enabling generalizability

> çœ‹ä¸ŠåŽ»ç»“æžœå¾ˆå®¹æ˜“å—åˆ° CPU ç¼“å­˜å½±å“ã€‚ä½†å‰æ–‡åˆè¯´å½±å“ä¸å¤§ï¼Ÿèƒ½å¤Ÿé¢„æµ‹ query runtime å’Œ workload

### OU-Model Generalization

For a state-of-the-art baseline, we compare against the **QPPNet ML model** for query performance prediction

QPPNet uses a tree-structured neural network to capture a query planâ€™s structural information. It outperforms other recent models on predicting query runtime especially when generalizing the trained model to different workloads (e.g., changing dataset sizes)

Since NoisePage is an **in-memory DBMS** with a **fused-operator JIT query engine**, we remove any **disk-oriented features** from QPPNetâ€™s inputs and adapt its operator-level tree structure to support pipelines. But such adaptation requires QPPNetâ€™s training data to contain all the operator combinations in the test data pipelines to do inference with the proper tree structure. Thus, we can only train QPPNet on more complex workloads (e.g., TPC-C) and test on the same or simpler workloads (e.g., SmallBank)

> è¿˜æ˜¯å¼ºè°ƒäº† NoisePage æ˜¯å†…å­˜æ•°æ®åº“ï¼Œè€Œä¸”æ˜¯ JIT çš„

We evaluate MB2 and QPPNet on the (1) TPC-H OLAP workload and (2) TPC-C, TATP, and SmallBank OLTP workloads. To evaluate **generalizability**, we first train a QPPNet model with query metrics from a 1 GB TPC-H dataset and evaluate it on two other dataset sizes (i.e., 0.1 GB, 10 GB).

> åœ¨ TPCH ä¸Šè®­ç»ƒå’Œè¯„ä¼°ã€‚QPPNET çš„å‡†ç¡®æ€§éžå¸¸å¥½ï¼Œä½†åœ¨å…¶ä»–æ•°æ®é›†ä¸Šé”™è¯¯çŽ‡å¾ˆé«˜ã€‚
>
> è€Œ MB2 æ¯” QPPNET é«˜ 25x çš„ç²¾åº¦ï¼Œå¹¶ä¸”æ‰€æœ‰ workload size ä¸Šé¢„æµ‹çš„ç²¾ç¡®åº¦éƒ½å¾ˆç¨³å®šã€‚

We attribute this difference to how (1) MB2 **decomposes** the DBMS into **fine-grained OUs** and the corresponding OU-runner enumerates various input features that cover a range of workloads, and (2) MB2â€™s output **label normalization** technique further bolsters OU-modelsâ€™ generalizability.

> æœ€é‡è¦çš„ä¸¤ä¸ªå› ç´ ï¼Œåˆ†è§£æˆå°çš„ OUï¼Œå°†ç»“æžœ label normalizationï¼Œæ‰€ä»¥èƒ½å¤Ÿæ³›åŒ–ã€‚

Even though the 10 GB TPC-H workload has tables up to **60m tuples**, which is 60Ã— larger than the largest table considered by MB2â€™s OU-runners, MB2 is still able to **generalize with minimal loss of accuracy**. MB2 without the output normalization has much worse accuracy on large datasets.

> å†æ¬¡å¼ºè°ƒ normalization çš„é‡è¦æ€§

### Interference Model Accuracy

We next measure the ability of MB2â€™s interference model to capture the impact of resource competition on concurrent OUs. We run the concurrent runner with the 1 GB TPC-H benchmark since it contains a diverse set of OUs. The concurrent runner enumerates three parameters: (1) **subsets of TPC-H queries**, (2) **number of concurrent threads**, and (3) **query arrival rate**.

Since the interference model is not specific to any OU or DBMS configuration, the concurrent runner does not need to exercise all OU-model inputs or knobs. For example, with the knob that controls the number of threads, we only generate training data for odd-numbered settings (i.e., 1, 3, 5, . . . 19) and then test on even-numbered settings. The concurrent runner executes each query setup for 20s. To reduce the evaluation time, we assume the average query arrival rate per query template per 10s is given to the model. In practice, this interval can be larger. Neural network performs the best for this model given its capacity to consume the summary statistics of OU-model output labels

To evaluate the modelâ€™s generalizability, the concurrent runner executes queries only in the **DBMSâ€™s interpretive mode** (execution knob discussed in Sec. 4.2), but we test the model under **JIT compilation mode**. We also evaluate the model with thread numbers and workload sizes that are different from those used by MB2â€™s concurrent runners. To isolate the interference modelâ€™s estimation, we execute the queries in both single-thread and concurrent environments and compare the true adjustment factors (the concurrent interference impact) against the predicted adjustment factors

> ä»€ä¹ˆæ˜¯ interpretive modeï¼Ÿ

the **actual and interference model-estimated average query run times under concurrent environments**. The interference model has less than 20% error in all cases. It generalizes to these environments because (1) it leverages **summary statistics** of the OU-model **output labels** that are agnostic to specific OUs and (2) the **elapsed time-based input normalization** and ratio-based output labels help the model generalize across various scenarios. We also observe that generalizing the interference model to small data sizes result in the highest error (shown under TPC-H 0.1 GB in Fig. 8b) since the queries are shorter with potentially higher variance in the interference, especially since the model only has the average query arrival information in an interval as an input feature

> è¿˜æ˜¯ normalization

### Model Adaptation and Robustness

å™ªå£°å½±å“ï¼Œnoisy estimation

### Hardware Context

Since MB2 **generates models offline**, their predictions may be inaccurate when the hardware used for training data generation and production differs.

> åœ¨ä¸åŒçš„ CPU é¢‘çŽ‡ä¸Šè®­ç»ƒï¼Œå¸¦æ¥çš„è¯¯å·®ä¹Ÿä¸åŒï¼Œè€Œä¸”çœ‹ä¸ŠåŽ»å—å½±å“å¾ˆå¤§ï¼Ÿä½†ä¸ºä»€ä¹ˆæ˜¯è·Ÿä¸»é¢‘æœ‰å…³ï¼Ÿæ˜¯å› ä¸ºè®­ç»ƒçš„æ—¶å€™ï¼Œé”™è¯¯ä¼°è®¡äº†æŸ¥è¯¢æ—¶é—´å—ï¼Ÿæ‰€ä»¥å¯ä»¥æ‰©å±•å¤šä¸€äº›å‚æ•°å—ï¼Ÿ

### End-to-End Self-Driving Execution

demonstrate MB2â€™s **behavior modelsâ€™** application for a **self-driving DBMSâ€™s planning components** and show how it enables interpretation of its **decision-making process**. We assume that the DBMS has (1) workload forecasting information of average query arrival rate per query template in each 10s forecasting interval. and (2) an â€œoracleâ€ planner that makes decisions using predictions from behavior models. We assume a perfect workload forecast to isolate MB2â€™s prediction error

> åˆ›å»ºç´¢å¼•æ—¶ï¼Œruntimeï¼Œcpu å ç”¨çŽ‡éƒ½é¢„æµ‹å¾—å¾ˆå¥½ï¼Œæ˜¯ self-driving database çš„åŸºç¡€

This example demonstrates that MB2â€™s **behavior models accurately estimate the cost, impact, and benefit of actions for self-driving DBMSs** ahead of time given the workload forecasting, which is a foundational step towards building a self-driving DBMS

demonstrate MB2â€™s **estimations** under an alternative action plan of the self-driving DBMS in Fig. 11c. The DBMS plans the same actions under the same setup as in Fig. 11a except to build the index earlier (at 58s) with four threads to reduce the impact on the running workload. MB2 **accurately estimates the smaller query runtime** increment along with the workload being impacted for longer. Such a **trade-off** between action time and workload impact is essential information for a self-driving DBMS to plan for target objectives (e.g., SLAs). We also observe that MB2 underestimates the index build time under this scenario by 27% due to a combination of OU and interference-model errors.

> ä½†ä¹Ÿå­˜åœ¨é¢„æµ‹é”™è¯¯çš„æƒ…å†µ

## RELATED WORK

We broadly classify the previous work in DBMS modeling into the following categories:

1. ML models
2. analytical models.

Related to this are other methods **for handling concurrent workloads**. We also discuss other efforts on **building automated DBMSs and reinforcement learning-based approaches**

**Machine Learning Models**: Most ML-based behavior models use **query plan information** as input features for estimating system performance.

> ML æ–¹æ³•éœ€è¦å¼€å‘äººå‘˜è°ƒæ•´ feature, æ”¶é›†æ•°æ®ï¼Œé‡æ–°è®­ç»ƒä»¥é€‚åº”æ–°çŽ¯å¢ƒã€‚å¹¶ä¸”å¾ˆå¤š ML æ¨¡åž‹éƒ½æ˜¯åœ¨åˆæˆçš„å° benchmark ä¸Šè¿›è¡Œçš„ï¼Œæ‰€ä»¥åœ¨å…¶ä»– workload ä¸Šæœ‰å¾ˆå¤§çš„é¢„æµ‹é”™è¯¯ã€‚å¹¶ä¸”ä¸æ”¯æŒäº‹åŠ¡ workloadsï¼Œå¹¶ä¸”å¿½ç•¥äº† DBMS å†…éƒ¨æ“ä½œã€‚è€Œ MB2 å°±æ‹†åˆ†äº†å°çš„ OU æ“ä½œï¼Œå¹¶ä¸”ç”¨ SQL æ‰€ä»¥åªç”¨å°‘é‡é‡æ–°è®­ç»ƒï¼Œè€Œä¸”é€‚åº”æ›´æ–°ã€‚

**Analytical Models**: Researchers have also built analytical models for DBMS components.

**Concurrent Queries**: Due to the difficulty of modeling concurrent operations as described in Sec. 2.2, the aforementioned techniques largely focus on performance prediction for one query at a time. For concurrent OLAP workloads, researchers have built sampling- based statistical models that are fixed for a known set of queries.

**Autonomous DBMSs**: There is a long history of research on automating DBMS deployments

> è¿™é‡Œä¹Ÿæåˆ°äº†åŒæ ·æ˜¯ CMU çš„ Ottertuneï¼Œä½† Ottertune æ˜¯ Gaussian Process Regression to model how a DBMS will perform with different knob settings.

**Reinforcement Learning (RL) for DBMSs**: Recent work ex- plores using RL [55, 59] to enhance individual DBMS components [39, 48, 75], which **are independent of MB2â€™s goal to build behavior models for self-driving DBMSs that automate all the administrative tasks**. We use a modularized design (Sec. 2) for self-driving DBMSs, which has a different methodology than RL-based approaches. We think this approach provides better data efficiency, debuggability, and explainability, which are essential for the systemâ€™s practical application. All major organizations working on self-driving cars also use a modularized approach instead of end-to-end RL

> æ²¡ç†è§£ä¸ºä»€ä¹ˆç”¨æ¨¡å—åŒ–æ–¹æ³•è€Œä¸æ˜¯ç«¯åˆ°ç«¯ RL

## CONCLUSION

**Behavior modeling** is the foundation for building a self-driving DBMS. We propose a modeling framework ModelBot2 (MB2) that decomposes the DBMS into operating units (OUs) and builds models for each OU with runners that exercise OUsâ€™ behavior. Our evalua- tion shows that MB2â€™s behavior models provide the essential cost, impact, and benefit estimations for actions of self-driving DBMSs and generalize to various workloads and environments.

> ä¸»è¦è®²äº†æ€Žä¹ˆå»ºæ¨¡ behavior modelï¼Œæ€Žä¹ˆæ‹†åˆ† Operation Unit ç„¶åŽç”¨ ML æ–¹æ³•åšé¢„æµ‹ï¼Œè¿˜æœ‰å¾ˆé‡è¦çš„ normalizationã€‚ç»“åˆèµ·æ¥å°±æ˜¯ self-driving DBMS çš„åŸºç¡€ã€‚
>
> ä¸­é—´å¾ˆå¤šåœ°æ–¹æ²¡æ€Žä¹ˆçœ‹æ‡‚ï¼Œå¥½åƒå°±æ˜¯åœ¨ç‰¹æ®Šçš„æ•°æ®åº“ä¸Šæ‹†å‡ºå„ç§å•å…ƒä»»åŠ¡ï¼Œç”¨å„ç§ä¸åŒçš„ ML æ–¹æ³•é¢„æµ‹ï¼Œç„¶åŽ normalize ç»“æžœã€‚ä½† normalize éƒ¨åˆ†ä¸å¤ªæ¸…æ¥šï¼Œæ€Žä¹ˆé€‰ ML æ–¹æ³•çœ‹ä¸ŠåŽ»ä¹ŸçŽ„å­¦ã€‚OU é€‰çš„ä¹ŸæŒºå°‘çš„ï¼Œè€Œä¸”æ— æ³•å¤„ç† disk-oriented DBMSï¼Œå‡è®¾è¿˜æ˜¯æŒºå¼ºçš„ã€‚
>
> è®©æ•°æ®åº“è‡ªåŠ¨é©¾é©¶è¿˜æ˜¯éžå¸¸å¸å¼•äººçš„ï¼Œå°¤å…¶æ˜¯ä¼˜åŒ–ã€‚ä½†æ•°æ®åº“è¿˜æ˜¯å¤ªå¤æ‚äº†ï¼Œä¸€ä¸ªæ¡†æž¶æ— æ³•å¤„ç†æ‰€æœ‰çš„æƒ…å†µï¼Œè€Œä¸”æ•°æ®éžå¸¸éš¾æ”¶é›†ï¼Œä¸åŒæ•°æ®ä¸åŒæ–¹æ³•ä¹Ÿå·®å¼‚å¾ˆå¤§ï¼Œè®ºæ–‡å¾ˆæœ‰æ„æ€çš„ä¸€ç‚¹å°±æ˜¯ç”¨æ±½è½¦çš„è‡ªåŠ¨é©¾é©¶ç±»æ¯”æ•°æ®åº“çš„è‡ªåŠ¨é©¾é©¶ï¼Œæ˜¯å¾ˆç›¸ä¼¼çš„ï¼Œéƒ½éœ€è¦æ„ŸçŸ¥ï¼ŒçŸ¥é“æœ‰ä»€ä¹ˆå·¥ä½œè´Ÿè½½ï¼Œä¹Ÿéœ€è¦é¢„æµ‹æœªæ¥çš„å·¥ä½œè´Ÿè½½ï¼Œä½¿å…¶èƒ½å¤ŸçŸ¥é“æ€Žä¹ˆä¼˜åŒ–ã€‚ç¬¬äºŒæ­¥å°±æ˜¯ä¼˜åŒ–ï¼Œæ¯”å¦‚å»ºç´¢å¼•ã€è°ƒå‚æ•°ï¼Œç¬¬ä¸‰æ­¥æ˜¯éœ€è¦çŸ¥é“åœ¨ä»€ä¹ˆæ—¶å€™ä¼˜åŒ–ï¼Œæ¯”å¦‚è´Ÿè½½ä½Žçš„æ—¶å€™å»ºç«‹ç´¢å¼•ï¼Œè¿˜è¦çŸ¥é“æ“ä½œå¸¦æ¥çš„å½±å“ã€‚
>
> å†ä¸€ä¸ªæ¯”è¾ƒé‡è¦çš„åœ°æ–¹æ˜¯ï¼ŒMB2 è€ƒè™‘äº†å¤šçº¿ç¨‹å¹¶å‘çš„æƒ…å†µï¼Œè¿™å¾ˆé‡è¦ï¼Œå°¤å…¶æ˜¯çŽ°åœ¨çš„æ•°æ®åº“å¤§éƒ¨åˆ†éƒ½æ˜¯æ”¯æŒå¹¶å‘çš„ã€‚
>
> MB2 å®žé™…ä¸Šæ˜¯ç»“åˆäº†æœºå™¨å­¦ä¹ å»ºæ¨¡å’Œåˆ†æžæ–¹æ³•å»ºæ¨¡ï¼Œä½†å¤§éƒ¨åˆ†æƒ…å†µä¸‹ gradient boosting æ¨¡åž‹è¡¨çŽ°æœ€å¥½ï¼Œä½†æ˜¯æ˜¯æ ¹æ®æ€Žä¹ˆæŒ‡æ ‡æ¥ç¡®å®šçš„å‘¢ï¼Ÿ
>
> æ•°æ®å¯¹è‡ªæ²»æ•°æ®åº“çš„å®žçŽ°ä¹Ÿæ˜¯éžå¸¸é‡è¦çš„

> Summarize:
> The paper proposes a modeling framework called ModelBot2(MB2) for building a self-driving DBMS. MB2 decomposes DBMS into many fine-grained and independent operating units(OUs) such as building a hash table and interference model for concurrent operations such as log record flush. MB2 trains these models with different ML methods like gradient boosting, and use different input features to estimate system performance metrics. The experiment result shows that MB2 is able to predict DBMS performance more accurately than the state-of-the-art ML models called QPPNet, especially under dynamic different workload scenarios. MB2 performs behavioral modeling on DBMS and predicts the impact and benefit of automated operations of various datasets(OLAP and OLTP), which is foundational for establishing an self-driving database.

> Contributions:
>
> 1. MB2 breaks down the database management system's functionality into smaller, independent units called operating units (OUs), each OU can have a model trained to predict its runtime and resource consumption. Using decomposed OUs to build behavioral models not only reduces the high-dimensionality of the problem, but each OU requires less training data and gives more fine-grained predictions.
> 2. MB2 also proposes a interference model, which captures contention on locks and data structures through individual OU models. Additionally, a separate interference model is designed to predict contention on hardware resources such as memory, CPU, and I/O. This model outputs summary statistics to generalize to various concurrent OUs.
> 3. MB2 integrates the behavior model and interference model with NoisePage, which is a relational database management system from CMU. MB2 can predict the systemâ€™s performance for OLTP, OLAP and even mixed workloads in dynamic environments, while most ML-based models do not support transcational workloads. MB2 achieves this by applying output normalization techniques, and it outperforms QPPNet particularly in terms of generalizability and performance across different workloads.

> Limitations:
>
> 1. MB2 is limited to train on an offline enviornment. Though MB2 is adaptive to dynamic workload and even transcational workload, it still needs retrain when there are some DBMS updates. I'm not an expert in database tuning, but maybe some OUs in MB2 still need to be retrained when knobs and configurations are changed.
> 2. MB2 is not be directly designed for predicting disk-oriented database performance, and it uses in-memory database. Since MB2 might not be able to predict the cache content in CPU cache runs or buffer pool. And MB2 needs warm up and enough repetitions to be able to predict accurately. This may cause the CPU cache and buffer pool to cache a lot of data, resulting in inaccurate predictions.
> 3. MB2 is designed to be a self-driving DBMS, however, the initial setup of MB2 needs developers to decompose the DBMSâ€™s architecture into operating units(OUs), which requires professional database administrators. And MB2 seems to have poor cross-platform capabilities, when the CPU frequency changes, the prediction ability changes greatly.

> Improve:
>
> The paper makes an analogy between self-driving vehicles and databases. It is a very good paper. I might try to improve it based on several limitations of MB2. First, I would try to extend MB2's capabilities to disk-oriented DBMS, it would be necessary to incorporate models that understand and predict disk I/O operations and the cached content. It might need to develop hybrid models that can handle both in-memory and disk-based operations, apply more ML methods to predict cached contents. What's more, MB2 could be improved by implementing online learning algorithms that can update the models in real-time for database updates or new workloads. Finally, I will try to enhance MB2 to adapt to different CPU frequencies, it might involve creating models that factor in CPU performance metrics and how they affect DBMS operations.
